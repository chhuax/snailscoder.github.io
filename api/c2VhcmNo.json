[{"title":"【转】通过源码一步步分析ArrayList扩容机制","date":"2020-04-14T11:55:25.000Z","date_formatted":{"ll":"2020年4月14日","L":"2020/04/14","MM-DD":"04-14"},"updated":"2020-04-14T04:03:26.717Z","content":"一 先从 ArrayList 的构造函数说起ArrayList有三种方式来初始化，构造方法源码如下：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/**  * 默认初始容量大小  */ private static final int DEFAULT_CAPACITY = 10;  private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /**  *默认构造函数，使用初始容量10构造一个空列表(无参数构造)  */ public ArrayList() &#123;     this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125;  /**  * 带初始容量参数的构造函数。（用户自己指定容量）  */ public ArrayList(int initialCapacity) &#123;     if (initialCapacity &gt; 0) &#123;//初始容量大于0         //创建initialCapacity大小的数组         this.elementData = new Object[initialCapacity];     &#125; else if (initialCapacity == 0) &#123;//初始容量等于0         //创建空数组         this.elementData = EMPTY_ELEMENTDATA;     &#125; else &#123;//初始容量小于0，抛出异常         throw new IllegalArgumentException(\"Illegal Capacity: \"+                                            initialCapacity);     &#125; &#125;/** *构造包含指定collection元素的列表，这些元素利用该集合的迭代器按顺序返回 *如果指定的集合为null，throws NullPointerException。  */  public ArrayList(Collection&lt;? extends E&gt; c) &#123;     elementData = c.toArray();     if ((size = elementData.length) != 0) &#123;         // c.toArray might (incorrectly) not return Object[] (see 6260652)         if (elementData.getClass() != Object[].class)             elementData = Arrays.copyOf(elementData, size, Object[].class);     &#125; else &#123;         // replace with empty array.         this.elementData = EMPTY_ELEMENTDATA;     &#125; &#125;细心的同学一定会发现 ：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10。 下面在我们分析 ArrayList 扩容时会讲到这一点内容！\n二 一步一步分析 ArrayList 扩容机制这里以无参构造函数创建的 ArrayList 为例分析\n1. 先来看 add 方法12345678910 /**  * 将指定的元素追加到此列表的末尾。   */ public boolean add(E e) &#123;//添加元素之前，先调用ensureCapacityInternal方法     ensureCapacityInternal(size + 1);  // Increments modCount!!     //这里看到ArrayList添加元素的实质就相当于为数组赋值     elementData[size++] = e;     return true; &#125;2. 再来看看 ensureCapacityInternal() 方法可以看到 add 方法 首先调用了ensureCapacityInternal(size + 1)\n123456789//得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123;     if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;           // 获取默认的容量和传入参数的较大值         minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);     &#125;     ensureExplicitCapacity(minCapacity); &#125;当 要 add 进第1个元素时，minCapacity为1，在Math.max()方法比较后，minCapacity 为10。\n3. ensureExplicitCapacity() 方法如果调用 ensureCapacityInternal() 方法就一定会进过（执行）这个方法，下面我们来研究一下这个方法的源码！\n123456789//判断是否需要扩容  private void ensureExplicitCapacity(int minCapacity) &#123;      modCount++;      // overflow-conscious code      if (minCapacity - elementData.length &gt; 0)          //调用grow方法进行扩容，调用此方法代表已经开始扩容了          grow(minCapacity);  &#125;我们来仔细分析一下：\n当我们要 add 进第1个元素到 ArrayList 时，elementData.length 为0 （因为还是一个空的 list），因为执行了 ensureCapacityInternal() 方法 ，所以 minCapacity 此时为10。此时，minCapacity - elementData.length &gt; 0成立，所以会进入 grow(minCapacity) 方法。当add第2个元素时，minCapacity 为2，此时e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length &gt; 0 不成立，所以不会进入 （执行）grow(minCapacity) 方法。添加第3、4···到第10个元素时，依然不会执行grow方法，数组容量都为10。直到添加第11个元素，minCapacity(为11)比elementData.length（为10）要大。进入grow方法进行扩容。\n4. grow() 方法123456789101112131415161718192021222324/** * 要分配的最大数组大小 */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * ArrayList扩容的核心方法。 */private void grow(int minCapacity) &#123;    // oldCapacity为旧容量，newCapacity为新容量    int oldCapacity = elementData.length;    //将oldCapacity 右移一位，其效果相当于oldCapacity /2，    //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);    //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;   // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，   //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    // minCapacity is usually close to size, so this is a win:    elementData = Arrays.copyOf(elementData, newCapacity);&#125;int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity为偶数就是1.5倍，否则是1.5倍左右）！  奇偶不同，比如 ：10+10/2 = 15, 33+33/2=49。如果是奇数的话会丢掉小数.\n\n  “&gt;&gt;”（移位运算符）：&gt;&gt;1 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 　\n\n我们再来通过例子探究一下grow() 方法 ：\n当add第1个元素时，oldCapacity 为0，经比较后第一个if判断成立，newCapacity = minCapacity(为10)。但是第二个if判断不会成立，即newCapacity 不比 MAX_ARRAY_SIZE大，则不会进入 hugeCapacity 方法。数组容量为10，add方法中 return true,size增为1。当add第11个元素进入grow方法时，newCapacity为15，比minCapacity（为11）大，第一个if判断不成立。新容量没有大于数组最大size，不会进入hugeCapacity方法。数组容量扩为15，add方法中return true,size增为11。以此类推······这里补充一点比较重要，但是容易被忽视掉的知识点：\njava 中的 length属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性.java 中的 length() 方法是针对字符串说的,如果想看这个字符串的长度则用到 length() 这个方法.java 中的 size() 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!5. hugeCapacity() 方法。从上面 grow() 方法源码我们知道： 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) hugeCapacity() 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，如果minCapacity大于最大容量，则新容量则为Integer.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 Integer.MAX_VALUE - 8。 \n1234567891011private static int hugeCapacity(int minCapacity) &#123;    if (minCapacity &lt; 0) // overflow        throw new OutOfMemoryError();    //对minCapacity和MAX_ARRAY_SIZE进行比较    //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小    //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小    //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;    return (minCapacity &gt; MAX_ARRAY_SIZE) ?        Integer.MAX_VALUE :        MAX_ARRAY_SIZE;&#125;三 System.arraycopy() 和 Arrays.copyOf()方法阅读源码的话，我们就会发现 ArrayList 中大量调用了这两个方法。比如：我们上面讲的扩容操作以及add(int index, E element)、toArray() 等方法中都用到了该方法！\n3.1 System.arraycopy() 方法123456789101112131415/** * 在此列表中的指定位置插入指定的元素。  *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123;    rangeCheckForAdd(index);    ensureCapacityInternal(size + 1);  // Increments modCount!!    //arraycopy()方法实现数组自己复制自己    //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量；    System.arraycopy(elementData, index, elementData, index + 1, size - index);    elementData[index] = element;    size++;&#125;我们写一个简单的方法测试以下：\n1234567891011121314151617public class ArraycopyTest &#123;\tpublic static void main(String[] args) &#123;\t\t// TODO Auto-generated method stub\t\tint[] a = new int[10];\t\ta[0] = 0;\t\ta[1] = 1;\t\ta[2] = 2;\t\ta[3] = 3;\t\tSystem.arraycopy(a, 2, a, 3, 3);\t\ta[2]=99;\t\tfor (int i = 0; i &lt; a.length; i++) &#123;\t\t\tSystem.out.println(a[i]);\t\t&#125;\t&#125;&#125;结果：\n10 1 99 2 3 0 0 0 0 03.2 Arrays.copyOf()方法1234567/**  以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; 返回的数组的运行时类型是指定数组的运行时类型。   */ public Object[] toArray() &#123; //elementData：要复制的数组；size：要复制的长度     return Arrays.copyOf(elementData, size); &#125;个人觉得使用 Arrays.copyOf()方法主要是为了给原有数组扩容，测试代码如下：\n1234567891011public class ArrayscopyOfTest &#123;\tpublic static void main(String[] args) &#123;\t\tint[] a = new int[3];\t\ta[0] = 0;\t\ta[1] = 1;\t\ta[2] = 2;\t\tint[] b = Arrays.copyOf(a, 10);\t\tSystem.out.println(\"b.length\"+b.length);\t&#125;&#125;结果：\n1103.3 两者联系和区别联系： \n看两者源代码可以发现 copyOf() 内部实际调用了 System.arraycopy() 方法 \n区别：\narraycopy() 需要目标数组，将原数组拷贝到你自己定义的数组里或者原数组，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf() 是系统自动在内部新建一个数组，并返回该数组。\n四 ensureCapacity方法ArrayList 源码中有一个 ensureCapacity 方法不知道大家注意到没有，这个方法 ArrayList 内部没有被调用过，所以很显然是提供给用户调用的，那么这个方法有什么作用呢？\n1234567891011121314151617/**如有必要，增加此 ArrayList 实例的容量，以确保它至少可以容纳由minimum capacity参数指定的元素数。 * * @param   minCapacity   所需的最小容量 */public void ensureCapacity(int minCapacity) &#123;    int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)        // any size if not default element table        ? 0        // larger than default for default empty table. It's already        // supposed to be at default size.        : DEFAULT_CAPACITY;    if (minCapacity &gt; minExpand) &#123;        ensureExplicitCapacity(minCapacity);    &#125;&#125;最好在 add 大量元素之前用 ensureCapacity 方法，以减少增量重新分配的次数\n我们通过下面的代码实际测试以下这个方法的效果：\n12345678910111213public class EnsureCapacityTest &#123;\tpublic static void main(String[] args) &#123;\t\tArrayList&lt;Object&gt; list = new ArrayList&lt;Object&gt;();\t\tfinal int N = 10000000;\t\tlong startTime = System.currentTimeMillis();\t\tfor (int i = 0; i &lt; N; i++) &#123;\t\t\tlist.add(i);\t\t&#125;\t\tlong endTime = System.currentTimeMillis();\t\tSystem.out.println(\"使用ensureCapacity方法前：\"+(endTime - startTime));\t&#125;&#125;运行结果：\n1使用ensureCapacity方法前：21581234567891011121314public class EnsureCapacityTest &#123;    public static void main(String[] args) &#123;        ArrayList&lt;Object&gt; list = new ArrayList&lt;Object&gt;();        final int N = 10000000;        list = new ArrayList&lt;Object&gt;();        long startTime1 = System.currentTimeMillis();        list.ensureCapacity(N);        for (int i = 0; i &lt; N; i++) &#123;            list.add(i);        &#125;        long endTime1 = System.currentTimeMillis();        System.out.println(\"使用ensureCapacity方法后：\"+(endTime1 - startTime1));    &#125;&#125;运行结果：\n12使用ensureCapacity方法前：1773通过运行结果，我们可以看出向 ArrayList 添加大量元素之前最好先使用ensureCapacity 方法，以减少增量重新分配的次数。\n转自:通过源码一步步分析ArrayList扩容机制\n","plink":"https://snailscoder.com/2020/04/14/java/arraylist-grow/"},{"title":"高并发系统：消息队列使用","date":"2020-04-13T17:30:00.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T15:18:07.410Z","content":"在历年的工作经历中，一直把消息队列看作暂时存储数据的一个容器，认为它是一个平衡低速系统和高速系统处理任务时间差的工具。我理解的消息队列在高并发系统设计中起到的作用的主要有以下三点：\n削峰填谷:可以削去到达秒杀系统的峰值流量，让业务逻辑的处理更加缓和，但会造成请求处理的延迟；异步处理:可以简化业务流程中的步骤，提升系统性能，但是你需要分清同步流程和异步流程的边界；解耦合:可以将秒杀系统和数据系统解耦开，这样两个系统的任何变更都不会影响到另一个系统。以秒杀场景为例：\n削峰填谷在秒杀场景下短时间之内数据库的写流量会很高，但高并发的写请求并不是持续的，也不是经常发生的，而只有在秒杀活动开始后的几秒或者十几秒时间内才会存在。在数据库层面下功夫来提高性能有点得不偿失。\n所以我们的思路是：将秒杀请求暂存在消息队列中，然后业务服务器会响应用户“秒杀结果正在计算中”，释放了系统资源之后再处理其它用户的请求。\n我们会在后台启动若干个队列处理程序消费消息队列中的消息，再执行校验库存、下单等逻辑。因为只有有限个队列处理线程在执行，所以落入后端数据库上的并发请求是有限的。而请求是可以在消息队列中被短暂地堆积，当库存被消耗完之后，消息队列中堆积的请求就可以被丢弃了。\n这就是消息队列在秒杀系统中最主要的作用：削峰填谷，也就是说它可以削平短暂的流量高峰，虽说堆积会造成请求被短暂延迟处理，但是只要我们时刻监控消息队列中的堆积长度，在堆积量超过一定量时，增加队列处理机数量来提升消息的处理能力就好了，而且秒杀的用户对于短暂延迟知晓秒杀的结果也是有一定容忍度的。\n这里需要注意一下，我所说的是“短暂”延迟，如果长时间没有给用户公示秒杀结果，那么用户可能就会怀疑你的秒杀活动有猫腻了。所以在使用消息队列应对流量峰值时，需要对队列处理的时间、前端写入流量的大小、数据库处理能力做好评估，然后根据不同的量级来决定部署多少台队列处理程序。\n异步处理其实在大量的写请求“攻击”你的电商系统的时候，消息队列除了发挥主要的削峰填谷的作用之外，还可以实现异步处理来简化秒杀请求中的业务流程，提升系统的性能。\n\n你想，在刚才提到的秒杀场景下，我们在处理购买请求时需要 500ms。这时你分析了一下整个的购买流程，发现这里面会有主要的业务逻辑，也会有次要的业务逻辑：比如说，主要的流程是生成订单、扣减库存；次要的流程可能是我们在下单购买成功之后会给用户发放优惠券，会增加用户的积分。\n解耦合除了异步处理和削峰填谷以外，消息队列在秒杀系统中起到的另一个作用是解耦合。\n比如数据团队对你说，在秒杀活动之后想要统计活动的数据，借此来分析活动商品的受欢迎程度、购买者人群的特点以及用户对于秒杀互动的满意程度等等指标。而我们需要将大量的数据发送给数据团队，那么要怎么做呢？\n一个思路是：使用 HTTP 或者 RPC 的方式来同步地调用，也就是数据团队这边提供一个接口，我们实时将秒杀的数据推送给它，但是这样调用会有两个问题：\n整体系统的耦合性比较强，当数据团队的接口发生故障时，会影响到秒杀系统的可用性。当数据系统需要新的字段，就要变更接口的参数，那么秒杀系统也要随着一起变更。这时，我们可以考虑使用消息队列降低业务系统和数据系统的直接耦合度。\n秒杀系统产生一条购买数据后，我们可以先把全部数据发送给消息队列，然后数据团队再订阅这个消息队列的话题，这样它们就可以接收到数据，然后再做过滤和处理了。\n秒杀系统在这样解耦合之后，数据系统的故障就不会影响到秒杀系统了，同时当数据系统需要新的字段时，只需要解析消息队列中的消息，拿到需要的数据就好了。\n\n总结消息队列在高并发系统设计中起到的作用以及一些注意事项，重点如下：\n削峰填谷是消息队列最主要的作用，但是会造成请求处理的延迟。异步处理是提升系统性能的神器，但是你需要分清同步流程和异步流程的边界，同时消息存在着丢失的风险，我们需要考虑如何确保消息一定到达。解耦合可以提升你的整体系统的鲁棒性。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/queue01.png","plink":"https://snailscoder.com/2020/04/13/architect/queue-01/"},{"title":"高并发系统：缓存使用-缓存穿透","date":"2020-04-13T14:30:20.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T06:33:19.935Z","content":"在低缓存命中率的系统中，大量查询信息的请求会穿透缓存到数据库，因为数据库对于并发的承受能力是比较脆弱的。一旦数据库承受不了，查询就会变慢，大量的请求也会阻塞在数据库查询上，造成应用服务器的连接和线程资源被占满，最终导致你的电商系统崩溃。\n一般来说，我们的核心缓存的命中率要保持在 99% 以上，非核心缓存的命中率也要尽量保证在 90%，如果低于这个标准你可能就需要优化缓存的使用方式了。\n什么是缓存穿透缓存穿透其实是指从缓存中没有查到数据，而不得不从后端系统（比如数据库）中查询的情况。\n互联网系统的数据访问模型一般会遵从“80/20 原则”。大部分流量都在 20% 的热点数据上，而另外的 80% 的数据则不会被经常访问。理论上说，我们只需要在有限的缓存空间里存储 20% 的热点数据就可以有效地保护脆弱的后端系统了，也就可以放弃缓存另外 80% 的非热点数据了。所以这种少量的缓存穿透是不可避免的，但是对系统是没有损害的。\n缓存穿透的解决方案那如何解决缓存穿透呢？一般来说我们会有两种解决方案：回种空值以及使用布隆过滤器。\n1、回种空值当我们从数据库中查询到空值或者发生异常时，我们可以向缓存中回种一个空值。但是因为空值并不是准确的业务数据，并且会占用缓存的空间，所以我们会给这个空值加一个比较短的过期时间，让空值在短时间之内能够快速过期淘汰。下面是这个流程的伪代码：\n1234567891011Object nullValue &#x3D; new Object();try &#123;  Object valueFromDB &#x3D; getFromDB(uid); &#x2F;&#x2F;从数据库中查询数据  if (valueFromDB &#x3D;&#x3D; null) &#123;    cache.set(uid, nullValue, 10);   &#x2F;&#x2F;如果从数据库中查询到空值，就把空值写入缓存，设置较短的超时时间  &#125; else &#123;    cache.set(uid, valueFromDB, 1000);  &#125;&#125; catch(Exception e) &#123;  cache.set(uid, nullValue, 10);&#125;回种空值缺点：虽然能够阻挡大量穿透的请求，但如果有大量不存在信息的查询请求，缓存内就会有有大量的空值缓存，也就会浪费缓存的存储空间，如果缓存空间被占满了，还会剔除掉一些已经被缓存的有效信息反而会造成缓存命中率的下降。所以这个方案，我建议你在使用的时候应该评估一下缓存容量是否能够支撑。\n2、使用布隆过滤器布隆过滤器说明1970 年布隆提出了一种布隆过滤器的算法，用来判断一个元素是否在一个集合中。这种算法由一个二进制数组和一个 Hash 算法组成。它的基本思路如下：我们把集合中的每一个值按照提供的 Hash 算法算出对应的 Hash 值，然后将 Hash 值对数组长度取模后得到需要计入数组的索引值，并且将数组这个位置的值从 0 改成 1。在判断一个元素是否存在于这个集合中时，你只需要将这个元素按照相同的算法计算出索引值，如果这个位置的值为 1 就认为这个元素在集合中，否则则认为不在集合中。下图是布隆过滤器示意图，我来带你分析一下图内的信息。\nA、B、C 等元素组成了一个集合，元素 D 计算出的 Hash 值所对应的的数组中值是 1，所以可以认为 D 也在集合中。而 F 在数组中的值是 0，所以 F 不在数组中。\n使用布隆过滤器来解决缓存穿透的问题还是以存储用户信息的表为例进行讲解。首先我们初始化一个很大的数组，比方说长度为 20 亿的数组，接下来我们选择一个 Hash 算法，然后我们将目前现有的所有用户的 ID 计算出 Hash 值并且映射到这个大数组中，映射位置的值设置为 1，其它值设置为 0。新注册的用户除了需要写入到数据库中之外，它也需要依照同样的算法更新布隆过滤器的数组中相应位置的值。那么当我们需要查询某一个用户的信息时，先查询这个 ID 在布隆过滤器中是否存在，如果不存在就直接返回空值，而不需要继续查询数据库和缓存，这样就可以极大地减少异常查询带来的缓存穿透。\n布隆过滤器拥有极高的性能，无论是写入操作还是读取操作，时间复杂度都是 O(1) 是常量值。在空间上，相对于其他数据结构它也有很大的优势，比如，20 亿的数组需要 2000000000/8/1024/1024 = 238M 的空间，而如果使用数组来存储，假设每个用户 ID 占用 4 个字节的空间，那么存储 20 亿用户需要 2000000000 * 4 / 1024 / 1024 = 7600M 的空间，是布隆过滤器的 32 倍。\n布隆过滤器缺陷1. 它在判断元素是否在集合中时是有一定错误几率的，比如它会把不是集合中的元素判断为处在集合中:    主要是 Hash 算法的问题，Hash 算法存在着一定的碰撞几率。但因为布隆过滤器的特点恰巧非常适合解决缓存穿透的问题。因为当布隆过滤器判断元素在集合中时，这个元素可能不在集合中。但是一旦布隆过滤器判断这个元素不在集合中时，它一定不在集合中。    当然如果在乎碰撞率问题，解决方案是：使用多个 Hash 算法为元素计算出多个 Hash 值，只有所有 Hash 值对应的数组中的值都为 1 时，才会认为这个元素在集合中。\n2. 不支持删除元素。布隆过滤器不支持删除元素的缺陷也和 Hash 碰撞有关。假如两个元素 A 和 B 都是集合中的元素，它们有相同的 Hash 值，它们就会映射到数组的同一个位置。这时我们删除了 A，数组中对应位置的值也从 1 变成 0，那么在判断 B 的时候发现值是 0，也会判断 B 是不在集合中的元素，就会得到错误的结论。解决方案是：将标志位0，1修改为计数方式。缺点是增加空间消耗。\n所以，你要依据业务场景来选择是否能够使用布隆过滤器\n总的来说，回种空值和布隆过滤器是解决缓存穿透问题的两种最主要的解决方案，但是它们也有各自的适用场景，并不能解决所有问题。\ndog-pile effect（狗桩效应）当有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力，我们把这个场景叫做“dog-pile effect”（狗桩效应），解决方案：\n在代码中控制在某一个热点缓存项失效之后启动一个后台线程，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都不再穿透而直接返回。通过在 Memcached 或者 Redis 中设置分布式锁，只有获取到锁的请求才能够穿透到数据库。综上回种空值是一种最常见的解决思路，实现起来也最简单，如果评估空值缓存占据的缓存空间可以接受，那么可以优先使用这种方案；布隆过滤器会引入一个新的组件，也会引入一些开发上的复杂度和运维上的成本。所以只有在存在海量查询数据库中，不存在数据的请求时才会使用，在使用时也要关注布隆过滤器对内存空间的消耗；对于极热点缓存数据穿透造成的“狗桩效应”，可以通过设置分布式锁或者后台线程定时加载的方式来解决。参考:布隆过滤器\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/caffeine.jpg","plink":"https://snailscoder.com/2020/04/13/architect/cache-03/"},{"title":"高并发系统：缓存使用-CDN静态缓存","date":"2020-04-13T14:30:20.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T07:12:51.826Z","content":"日常项目中存在哪些静态资源：\n对于移动 APP 来说，这些静态资源主要是图片、视频和流媒体信息；对于 Web 网站来说，则包括了 JavaScript 文件、CSS 文件、静态 HTML 文件等等。读请求量极大并且对访问速度的要求很高还占据了很高的带宽，这时会出现访问速度慢带宽被占满影响动态请求的问题，那么你就需要考虑如何针对这些静态资源进行读加速了。\nCDN 的关键技术CDN（Content Delivery Network/Content Distribution Network，内容分发网络）。简单来说，CDN 就是将静态的资源分发到位于多个地理位置机房中的服务器上，因此它能很好地解决数据就近访问的问题，也就加快了静态资源的访问速度。\n在大中型公司里面，CDN 的应用非常普遍，大公司为了提供更稳定的 CDN 服务会选择自建 CDN，而大部分公司基于成本的考虑还是会选择专业的 CDN 厂商，网宿、阿里云、腾讯云、蓝汛等等，其中网宿和蓝汛是老牌的 CDN 厂商，阿里云和腾讯云是云厂商提供的服务，如果你的服务部署在云上可以选择相应云厂商的 CDN 服务，这些 CDN 厂商都是现今行业内比较主流的。\n\n待补充。。。\n","plink":"https://snailscoder.com/2020/04/13/architect/cache-04/"},{"title":"高并发系统：缓存使用-读写策略","date":"2020-04-13T11:30:25.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T03:37:00.310Z","content":"我们在选择缓存读写策略时需要考虑诸多的因素，比如说，缓存中是否有可能被写入脏数据，策略的读写性能如何，是否存在缓存命中率下降的情况等等。我就以标准的“缓存 + 数据库”的场景为例，剖析经典的缓存读写策略以及它们适用的场景。这样一来，你就可以在日常的工作中根据不同的场景选择不同的读写策略。\n一、Cache Aside（旁路缓存）策略这个策略就是我们使用缓存最常见的策略，Cache Aside 策略（也叫旁路缓存策略），这个策略数据以数据库中的数据为准，缓存中的数据是按需加载的。\n它可以分为读策略和写策略其中读策略的步骤是：\n从缓存中读取数据；如果缓存命中，则直接返回数据；如果缓存不命中，则从数据库中查询数据；查询到数据后，将数据写入到缓存中，并且返回给用户。写策略的步骤是：\n更新数据库中的记录；删除缓存记录。\nCache Aside 策略是我们日常开发中最经常使用的缓存策略，不过我们在使用时也要学会依情况而变。比如说当新注册一个用户，按照这个更新策略，你要写数据库，然后清理缓存（当然缓存中没有数据给你清理）。可当我注册用户后立即读取用户信息，并且数据库主从分离时，会出现因为主从延迟所以读不到用户信息的情况。而解决这个问题的办法恰恰是在插入新数据到数据库之后写入缓存，这样后续的读请求就会从缓存中读到数据了。并且因为是新注册的用户，所以不会出现并发更新用户信息的情况。\nCache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：\n一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。\n二、Read/Write Through（读穿 / 写穿）策略这个策略的核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据。\n1、Write Through 策略先查询要写入的数据在缓存中是否已经存在\n如果已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中如果缓存中数据不存在，我们把这种情况叫做“Write Miss（写失效）”我们可以选择两种“Write Miss”方式：\n\nWrite Allocate（按写分配）:做法是写入缓存相应位置，再由缓存组件同步更新到数据库中；No-write allocate（不按写分配）:做法是不写入缓存中，而是直接更新到数据库中。\n\n在 Write Through 策略中，我们一般选择“No-write allocate”方式，原因是无论采用哪种“Write Miss”方式，我们都需要同步将数据更新到数据库中，而“No-write allocate”方式相比“Write Allocate”还减少了一次缓存的写入，能够提升写入的性能。\n2、Read Through 策略先查询缓存中数据是否存在\n如果存在则直接返回如果不存在，则由缓存组件负责从数据库中同步加载数据。\nRead Through/Write Through 策略的特点是由缓存节点而非用户来和数据库打交道，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库，或者自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略，比如说在上一节中提到的本地缓存 Guava Cache 中的 Loading Cache 就有 Read Through 策略的影子。\n\n三、Write Back（写回）策略这个策略的核心思想是在写入数据时只写入缓存，并且把缓存块儿标记为“脏”的。而脏块儿只有被再次使用时才会将其中的数据写入到后端存储中。\n这种策略不能被应用到我们常用的数据库和缓存的场景中，它是计算机体系结构中的设计，比如我们在向磁盘中写数据时采用的就是这种策略。无论是操作系统层面的 Page Cache，还是日志的异步刷盘，亦或是消息队列中消息的异步写入磁盘，大多采用了这种策略。因为这个策略在性能上的优势毋庸置疑，它避免了直接写磁盘造成的随机写问题，毕竟写内存和写磁盘的随机 I/O 的延迟相差了几个数量级呢。\n\n\n当然，你依然可以在一些场景下使用这个策略，在使用时，我想给你的落地建议是：你在向低速设备写入数据的时候，可以在内存里先暂存一段时间的数据，甚至做一些统计汇总，然后定时地刷新到低速设备上。比如说，你在统计你的接口响应时间的时候，需要将每次请求的响应时间打印到日志中，然后监控系统收集日志后再做统计。但是如果每次请求都打印日志无疑会增加磁盘 I/O，那么不如把一段时间的响应时间暂存起来，经过简单的统计平均耗时，每个耗时区间的请求数量等等，然后定时地，批量地打印到日志中。\n\n总结1.Cache Aside 是我们在使用分布式缓存时最常用的策略，你可以在实际工作中直接拿来使用。2.Read/Write Through 和 Write Back 策略需要缓存组件的支持，所以比较适合你在实现本地缓存组件的时候使用；3.Write Back 策略是计算机体系结构中的策略，不过写入策略中的只写缓存，异步写入后端存储的策略倒是有很多的应用场景。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/kafei.jpg","plink":"https://snailscoder.com/2020/04/13/architect/cache-02/"},{"title":"高并发系统：缓存简介","date":"2020-04-13T10:30:20.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T09:22:33.501Z","content":"什么是缓存缓存，是一种存储数据的组件，它的作用是让对数据的请求更快地返回。凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存。\n常见硬件组件的延时情况从这些数据中，你可以看到，做一次内存寻址大概需要 100ns，而做一次磁盘的查找则需要 10ms。如果我们将做一次内存寻址的时间类比为一个课间，那么做一次磁盘查找相当于度过了大学的一个学期。可见，我们使用内存作为缓存的存储介质相比于以磁盘作为主要存储介质的数据库来说，性能上会提高多个数量级，同时也能够支撑更高的并发量。所以，内存是最常见的一种缓存数据的介质。\n缓存分类在我们日常开发中，常见的缓存主要就是分布式缓存、热点本地缓存、静态缓存这几种。\n分布式缓存分布式缓存的大名可谓是如雷贯耳了，我们平时耳熟能详的 Memcached、Redis 就是分布式缓存的典型例子。它们性能强劲，通过一些分布式的方案组成集群可以突破单机的限制。所以在整体架构中，分布式缓存承担着非常重要的角色，后边细谈。\n热点本地缓存当我们遇到极端的热点数据查询的时候。热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中，优势是不需要跨网络调度，速度极快，所以可以用来阻挡短时间内的热点查询。Guava 的 Loading Cache代码样例：\n123456789CacheBuilder&lt;String, List&lt;Product&gt;&gt; cacheBuilder &#x3D; CacheBuilder.newBuilder().maximumSize(maxSize).recordStats(); &#x2F;&#x2F;设置缓存最大值cacheBuilder &#x3D; cacheBuilder.refreshAfterWrite(30, TimeUnit.Seconds); &#x2F;&#x2F;设置刷新间隔LoadingCache&lt;String, List&lt;Product&gt;&gt; cache &#x3D; cacheBuilder.build(new CacheLoader&lt;String, List&lt;Product&gt;&gt;() &#123;    @Override    public List&lt;Product&gt; load(String k) throws Exception &#123;        return productService.loadAll(); &#x2F;&#x2F; 获取所有商品    &#125;&#125;);由于本地缓存是部署在应用服务器中，而我们应用服务器通常会部署多台，当数据更新时，我们不能确定哪台服务器本地中了缓存，更新或者删除所有服务器的缓存不是一个好的选择，所以我们通常会等待缓存过期。因此，这种缓存的有效期很短，通常为分钟或者秒级别，以避免返回前端脏数据。\n静态缓存如CDN等，后续单独整理。\n缓存的不足首先，缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。这是因为缓存毕竟会受限于存储介质不可能缓存所有数据，那么当数据有热点属性的时候才能保证一定的缓存命中率其次，缓存会给整体系统带来复杂度，并且会有数据不一致的风险。当更新数据库成功，更新缓存失败的场景下，缓存中就会存在脏数据。对于这种场景，我们可以考虑使用较短的过期时间或者手动清理的方式来解决。再次，之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的。因此，我们在使用缓存的时候要做数据存储量级的评估，对于可预见的需要消耗极大存储成本的数据，要慎用缓存方案。同时，缓存一定要设置过期时间，这样可以保证缓存中的会是热点数据。最后，缓存会给运维也带来一定的成本。运维需要对缓存组件有一定的了解，在排查问题的时候也多了一个组件需要考虑在内。1虽然有这么多的不足，但是缓存对于性能的提升是毋庸置疑的，我们在做架构设计的时候也需要把它考虑在内，只是在做具体方案的时候需要对缓存的设计有更细致的思考，才能最大化地发挥缓存的优势。注意问题缓存可以有多层，比如上面提到的静态缓存处在负载均衡层，分布式缓存处在应用层和数据库层之间，本地缓存处在应用层。我们需要将请求尽量挡在上层，因为越往下层，对于并发的承受能力越差；缓存命中率是我们对于缓存最重要的一个监控项，越是热点的数据，缓存的命中率就越高当在实际工作中碰到“慢”的问题时，缓存就是你第一时间需要考虑的。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/huancun.png","plink":"https://snailscoder.com/2020/04/13/architect/cache-01/"},{"title":"高并发系统：数据迁移","date":"2020-04-12T20:59:00.000Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-13T09:22:21.675Z","content":"如何平滑地迁移数据库中的数据迁移过程需要满足以下几个目标：\n迁移应该是在线的迁移，也就是在迁移的同时还会有数据的写入；数据应该保证完整性，也就是说在迁移之后需要保证新的库和旧的库的数据是一致的；迁移的过程需要做到可以回滚，这样一旦迁移的过程中出现问题，可以立刻回滚到源库不会对系统的可用性造成影响。一般来说，我们有两种方案可以做数据库的迁移。\n“双写”方案\n将新的库配置为源库的从库用来同步数据；如果需要将数据同步到多库多表，那么可以使用一些第三方工具获取 Binlog 的增量日志（比如开源工具 Canal），在获取增量日志之后就可以按照分库分表的逻辑写入到新的库表中了。同时我们需要改造业务代码，在数据写入的时候不仅要写入旧库也要写入新库。当然，基于性能的考虑，我们可以异步地写入新库，只要保证旧库写入成功即可。但是我们需要注意的是，需要将写入新库失败的数据记录在单独的日志中，这样方便后续对这些数据补写，保证新库和旧库的数据一致性。然后我们就可以开始校验数据了。由于数据库中数据量很大，做全量的数据校验不太现实。你可以抽取部分数据，具体数据量依据总体数据量而定，只要保证这些数据是一致的就可以。如果一切顺利，我们就可以将读流量切换到新库了。由于担心一次切换全量读流量可能会对系统产生未知的影响，所以这里最好采用灰度的方式来切换，比如开始切换 10% 的流量，如果没有问题再切换到 50% 的流量，最后再切换到 100%。由于有双写的存在，所以在切换的过程中出现任何的问题都可以将读写流量随时切换到旧库去，保障系统的性能。在观察了几天发现数据的迁移没有问题之后，就可以将数据库的双写改造成只写新库，数据的迁移也就完成了。如果是将数据从自建机房迁移到云上，你也可以使用这个方案，只是你需要考虑的一个重要的因素是：自建机房到云上的专线的带宽和延迟，你需要尽量减少跨专线的读操作，所以在切换读流量的时候你需要保证自建机房的应用服务器读取本机房的数据库，云上的应用服务器读取云上的数据库。这样在完成迁移之前，只要将自建机房的应用服务器停掉并且将写入流量都切到新库就可以了。\n\n这种方案是一种比较通用的方案，无论是迁移 MySQL 中的数据还是迁移 Redis 中的数据，甚至迁移消息队列都可以使用这种方式，你在实际的工作中可以直接拿来使用。这种方式的好处是：迁移的过程可以随时回滚，将迁移的风险降到了最低。劣势是：时间周期比较长，应用有改造的成本。\n级联同步方案这种方案也比较简单，比较适合数据从自建机房向云上迁移的场景。因为迁移上云最担心云上的环境和自建机房的环境不一致，会导致数据库在云上运行时因为参数配置或者硬件环境不同出现问题。所以我们会在自建机房准备一个备库，在云上环境上准备一个新库，通过级联同步的方式在自建机房留下一个可回滚的数据库，具体的步骤如下：\n先将新库配置为旧库的从库，用作数据同步；再将一个备库配置为新库的从库，用作数据的备份；等到三个库的写入一致后，将数据库的读流量切换到新库；然后暂停应用的写入，将业务的写入流量切换到新库（由于这里需要暂停应用的写入，所以需要安排在业务的低峰期）。回滚过程如下：\n先将读流量切换到备库再暂停应用的写入将写流量切换到备库，这样所有的流量都切换到了备库，也就是又回到了自建机房的环境，就可以认为已经回滚了。这种方案优势是简单易实施，在业务上基本没有改造的成本；缺点是在切写的时候需要短暂的停止写入，对于业务来说是有损的，不过如果在业务低峰期来执行切写，可以将对业务的影响降至最低。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/114.png","plink":"https://snailscoder.com/2020/04/12/architect/db-06/"},{"title":"高并发系统：数据库优化-NoSQL补充","date":"2020-04-12T17:59:25.000Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-13T03:44:36.583Z","content":"NoSQL 数据库在性能、扩展性上的优势，以及它的一些特殊功能特性，主要有以下几点：\n在性能方面，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写，提升了写的性能；在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持；在扩展性方面，NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。NoSQL 数据库发展到现在，十几年间，出现了多种类型，我来给你举几个例子：\nRedis、LevelDB 这样的 KV 存储。这类存储相比于传统的数据库的优势是极高的读写性能，一般对性能有比较高的要求的场景会使用。Hbase、Cassandra 这样的列式存储数据库。这种数据库的特点是数据不像传统数据库以行为单位来存储，而是以列来存储，适用于一些离线数据统计的场景。MongoDB、CouchDB 这样的文档型数据库。这种数据库的特点是 Schema Free（模式自由），数据表中的字段可以任意扩展，比如说电商系统中的商品有非常多的字段，并且不同品类的商品的字段也都不尽相同，使用关系型数据库就需要不断增加字段支持，而用文档型数据库就简单很多了。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/buchong.jpg","plink":"https://snailscoder.com/2020/04/12/architect/db-05/"},{"title":"高并发系统：数据库优化-分库分表","date":"2020-04-12T12:59:25.000Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-13T03:47:26.437Z","content":"在 4 核 8G 的云服务器上对 MySQL 5.7 做 Benchmark，大概可以支撑 500TPS 和 10000QPS，如果出现写并发量大时，该如何解决？出现数据库容量瓶颈时如何解决？单纯从数据库层面考虑一般采用垂直拆分和水平拆分来解决。数据库分库分表的方式有两种：一种是垂直拆分，另一种是水平拆分。这两种方式，在我看来，掌握拆分方式是关键，理解拆分原理是内核。所以你在学习时，最好可以结合自身业务来思考。\n拆分方式1、垂直拆分垂直拆分，顾名思义就是对数据库竖着拆分，也就是将数据库的表拆分到多个不同的数据库中。垂直拆分的原则一般是按照业务类型来拆分，核心思想是专库专用，将业务耦合度比较高的表拆分到单独的库中。举个形象的例子，就是在整理衣服的时候，将羽绒服、毛衣、T 恤分别放在不同的格子里。这样可以解决我在开篇提到的第三个问题：把不同的业务的数据分拆到不同的数据库节点上，这样一旦数据库发生故障时只会影响到某一个模块的功能，不会影响到整体功能，从而实现了数据层面的故障隔离。现在大多数公司都采用微服务架构，一般方案为按服务拆库，各服务不进行跨库读写数据。\n优点：各业务库独立，可以按业务重要性来区别对待，优先保障核心业务库。缺点：不能解决某一个业务模块的数据大量膨胀的问题\n2、水平拆分和垂直拆分的关注点不同，垂直拆分的关注点在于业务相关性，而水平拆分指的是将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点。一般按业务类型分为两种拆分方式：\n字段哈希值拆分这种拆分规则比较适用于实体表，数据相对独立，无明显时间概念等的数据，比如说用户表，可以先对用户 ID 做哈希（哈希的目的是将 ID 尽量打散）比如拆分成16个库，每库64张表。先对库数量16取余，决定划分到哪个库，后对库中表数量64取余，决定在哪张表。\n字段区间拆分比较常用的是时间字段，比如用户订单等按照下单时间来拆分表，用户查询订单时必须指定查询时间段。该例子不一定是最优方案哈，会存在热点问题，比如双十一一天内订单量超大就会存在问题。\n分库分表引入的问题分库分表引入的一个最大的问题就是引入了分库分表键，也叫做分区键，也就是我们对数据库做分库分表所依据的字段。\n一旦分区后，查询条件中必须带有分区键查询，明确要查询的数据在哪个区才有效，否则会带来更严重的性能问题。现阶段如何解决跨区查询问题呢，本人总结方式如下：1、先查后整合    一般是把两个表的数据取出后在业务代码里面做筛选，复杂是有一些，不过是可以实现的。2、数据冗余    如用户表按用户ID拆分，但需要按用户昵称查询用户的情况。    可以冗余一份用户昵称与用户ID量字段的表，先从该表中按昵称查询ID，再进行ID精准查询。当然该表也可以进行分区。3、借助三方中间件    涉及一些复杂的查询搜索功能，可以借助ElasticSearch等中间件，来进行搜索优化。\n有很多人并没有真正从根本上搞懂为什么要拆分，拆分后会带来哪些问题，只是一味地学习大厂现有的拆分方法，从而导致问题频出。所以，你在使用一个方案解决一个问题的时候一定要弄清楚原理，搞清楚这个方案会带来什么问题，要如何来解决，要知其然也知其所以然，这样才能在解决问题的同时避免踩坑。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/109.jpg","plink":"https://snailscoder.com/2020/04/12/architect/db-04/"},{"title":"高并发系统：数据库优化-读写分离","date":"2020-04-12T10:49:25.000Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-12T04:21:17.229Z","content":"依据一些云厂商的 Benchmark 的结果，在 4 核 8G 的机器上运行 MySQL 5.7 时，大概可以支撑 500 的 TPS 和 10000 的 QPS。大部分系统的访问模型是读多写少，读写请求量的差距可能达到几个数量级。当单机MySQL达不到高并发读请求时的处理方案:主从读写分离\n主从读写的两个技术关键点一、主从复制MySQL 的主从复制是依赖于 binlog 的,主从复制就是将 binlog 中的数据从主库传输到从库上。具体过程：\n从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog，并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中而主库也会创建一个 log dump 线程来发送 binlog 给从库；从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性。这是一种比较常见的主从复制方式。主从复制存在的问题数据延时问题为了不影响主库的性能，主从同步为异步过程。不能保障从库无延时同步。主从的一致性和写入性能的权衡如果你要保证所有从节点都写入成功，那么写入性能一定会受影响；如果你只写入主节点就返回成功，那么从节点就有可能出现数据同步失败的情况，从而造成主从不一致，而在互联网的项目中，我们一般会优先考虑性能而不是数据的强一致性。不能无限制增加从库数量增加从库主库会创建log dump线程，消耗主库性能，一般一个主库最多挂 3～5 个从库主从数据延时解决方案参考\n1. 数据冗余    异步消息传输时，不仅仅发送ID，而是发送全量信息，避免从库再次查询.    缺点:可能造成单条消息比较大，从而增加了消息发送的带宽和时间。2. 使用缓存    同步写数据库的同时,将数据写入缓存:如Redis，从Redis中读取。    缺点:更适合新增数据，更新数据需要考虑数据不一致问题\n注意：需要做好从库延时时间的监控，延时过大需要告警通知。正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。\n\n二、程序访问一主多从，读写分离，存在多个数据库节点，程序需要选择性的连接，增加了访问的复杂度。为了降低实现的复杂度，业界涌现了很多数据库中间件来解决数据库的访问问题，这些中间件可以分为两类。\n1. 内嵌组件以淘宝的 TDDL为代表，以代码形式内嵌运行在应用程序内部，你可以把它看成是一种数据源的代理，它的配置管理着多个数据源，每个数据源对应一个数据库，可能是主库，可能是从库。当有一个数据库请求时，中间件将 SQL 语句发给某一个指定的数据源来处理，然后将处理结果返回。优点：简单易用，没有多余的部署成本缺点：缺乏多语言的支持，升级比较困难\n2. 增加代理层单独部署的代理层方案，中间件部署在独立的服务器上，业务代码如同在使用单一数据库一样使用它，实际上它内部管理着很多的数据源，当有数据库请求时，它会对 SQL 语句做必要的改写，然后发往指定的数据源。市面很多成熟中间件，具体可参考：分布式数据库中间件TDDL、Amoeba、Cobar、MyCAT架构比较\n优点：    * 使用标准的 MySQL 通信协议，所以可以很好地支持多语言    * 独立部署，维护升级方便缺点：    * 增加代理层，SQL多跨一层网络，有性能损耗    * 代理层专人维护成本增加\n注意：在使用任何中间件的时候一定要保证对于中间件有足够深入的了解，否则一旦出了问题没法快速地解决就悲剧了。\n\n名词解释QPS：每秒查询数，是针对读请求的TPS：每秒执行事务数，倾向于写请求binlog:记录 MySQL 上的所有变化并以二进制形式保存在磁盘上二进制日志文件扩展Redis主从复制原理总结","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/fenli.png","plink":"https://snailscoder.com/2020/04/12/architect/db-03/"},{"title":"高并发系统：池化技术-Tomcat、Undertow连接池","date":"2020-04-11T23:49:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:16:53.332Z","content":"Tomcat配置核心参数:max-threads:该线程池可以容纳的最大线程数。默认值：200server.tomcat.max-threads=1000max-connections:接受和处理的最大连接数server.tomcat.max-connections=20000min-SpareThreads:Tomcat应该始终打开的最小不活跃线程数。默认值：25。server.tomcat.min-SpareThreads=20acceptCount:可以放到处理队列中的请求数server.tomcat.acceptCount=700connectionTimeout 连接超时server.tomcat.connectionTimeout=1000\nUndertow配置核心参数io-threads:设置IO线程数, 它主要执行非阻塞的任务,它们会负责多个连接, 默认设置每个CPU核心一个线程.不要设置过大，如果过大，启动项目会报错：打开文件数过多server.undertow.io-threads=16\nworker-threads:阻塞任务线程池, 当执行类似servlet请求阻塞IO操作, undertow会从这个线程池中取得线程,它的值设置取决于系统线程执行任务的阻塞系数，默认值是IO线程数*8server.undertow.worker-threads=256\nbuffer-size:该配置会影响buffer,这些buffer会用于服务器连接的IO操作,有点类似netty的池化内存管理,每块buffer的空间大小,越小的空间被利用越充分，不要设置太大，以免影响其他应用，合适即可server.undertow.buffer-size=1024\nbuffers-per-region:每个区分配的buffer数量 , 所以pool的大小是buffer-size * buffers-per-regionserver.undertow.buffers-per-region=1024\ndirect-buffers:是否分配的直接内存(NIO直接分配的堆外内存)server.undertow.direct-buffers=true\n扩展文章SpringBoot服务器压测对比","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/qianbi.jpg","plink":"https://snailscoder.com/2020/04/11/architect/db-02/"},{"title":"高并发系统：池化技术-数据库连接池","date":"2020-04-11T22:49:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:16:58.028Z","content":"数据库连接池与系统线程池不同，数据库连接池并不控制应用端和数据库端的线程池的大小。而且每个数据库连接池的配置只是针对自己所在的应用服务进程，限制的是同一个进程内可以访问数据库的并行线程数目。\n数据库连接池好处节省了创建数据库连接的时间，通常这个时间大大超过处理数据访问请求的时间。统一管理数据库请求连接，避免了过多连接或频繁创建/删除连接带来的性能问题。监控了数据库连接的运行状态和错误报告，减少了应用服务的这部分代码。可以检查和报告不关闭数据库连接的错误，帮助运维监测数据库访问阻塞和帮助程序员写出正确数据库访问代码。连接池优化策略做为应用服务和数据库的桥梁，连接池参数配置的目标是全局优化。具体的优化目的有四个：\n尽可能满足应用服务的并发数据库访问所有需要访问数据库的线程都可以得到需要的数据库连接。如果一个线程用到多个连接，那么需要的连接数目也会成倍增加。这时，需要的连接池最大尺寸应该是最大的并发数据库访问线程数目乘以每个线程需要的连接数目。不让数据库服务器过载可能有多个应用服务器的多个连接池会同时发出请求。能发现用了不还造成的死锁应用程序错误会造成借了不还的情况，反复出现会造成连接池用完应用长期等待甚至死锁的状态。需要有连接借用的超时报错机制，而这个超时时间取决于具体应用。不浪费系统资源。配置过大的连接池会浪费应用服务器的系统资源，包括内存，网络端口，同步信号等。同时线程池的重启和操作都会响应变慢。不过应用端连接池的开销不是很大，资源的浪费通常不是太大问题。核心参数配置此处以Spring默认数据库连接池HikariCP为例：\nmaximum-pool-size:连接池中最大连接数（包括空闲和正在使用的连接）默认值是10，这个一般预估应用的最大连接数，后期根据监测得到一个最大值的一个平均值。要知道，最大连接并不是越多越好，一个connection会占用系统的带宽和存储。但是 当连接池没有空闲连接并且已经到达最大值，新来的连接池请求（HikariPool#getConnection）会被阻塞直到connectionTimeout（毫秒），超时后便抛出SQLException。minimum-idle:池中最小空闲连接数量。默认值10，小于池中最大连接数，一般根据系统大部分情况下的数据库连接情况取一个平均值。Hikari会尽可能、尽快地将空闲连接数维持在这个数量上。如果为了获得最佳性能和对峰值需求的响应能力，我们也不妨让他和最大连接数保持一致，使得HikariCP成为一个固定大小的数据库连接池。pool-name:连接池的名字。一般会出现在日志和JMX控制台中。默认值：auto-genenrated。建议取一个合适的名字，便于监控。auto-commit:是否自动提交池中返回的连接。默认值为true。一般是有必要自动提交上一个连接中的事务的。如果为false，那么就需要应用层手动提交事务。idle-timeout:空闲时间。仅在minimum-idle小于maximum-poop-size的时候才会起作用。默认值10分钟。根据应用实际情况做调整，对于一些间歇性流量达到峰值的应用，一般需要考虑设置的比间歇时间更大，防止创建数据库连接拖慢了应用速度。max-lifetime:连接池中连接的最大生命周期。当连接一致处于闲置状态时，数据库可能会主动断开连接。为了防止大量的同一时间处于空闲连接因为数据库方的闲置超时策略断开连接（可以理解为连接雪崩），一般将这个值设置的比数据库的“闲置超时时间”小几秒，以便这些连接断开后，HikariCP能迅速的创建新一轮的连接。connection-timeout:连接超时时间。默认值为30s，可以接收的最小超时时间为250ms。但是连接池请求也可以自定义超时时间（com.zaxxer.hikari.pool.HikariPool#getConnection(long)）。连接创建策略&lt;minimum-idle:如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；如果连接池中有空闲连接则复用空闲连接；&gt;minimum-idle,&lt;maximum-pool-size:如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；&gt;=maximum-pool-size:如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间等待旧的连接可用；如果等待超过了这个设定时间则向用户抛出错误。\n参考文章数据库连接池设置HikariCP重要参数配置","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/mg6431.jpg","plink":"https://snailscoder.com/2020/04/11/architect/db-01/"},{"title":"高并发系统：池化技术-JDK线程池","date":"2020-04-11T22:39:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:17:10.055Z","content":"JDK 实现的这个线程池优先把任务放入队列暂存起来，而不是创建更多的线程，它比较适用于执行 CPU 密集型的任务，也就是需要执行大量 CPU 运算的任务。这是为什么呢？因为执行 CPU 密集型的任务时 CPU 比较繁忙，因此只需要创建和 CPU 核数相当的线程就好了，多了反而会造成线程上下文切换，降低任务执行效率。所以当前线程数超过核心线程数时，线程池不会增加线程，而是放在队列里等待核心线程空闲下来。\n一般核心线程数与CPU核数一致，计算公式：线程数目 = CPU核数 * CPU 利用率 * (1 + 等待时间 / CPU计算时间)\nJDK线程池核心参数12345678&#x2F;&#x2F;java.util.concurrent.ThreadPoolExecutorpublic ThreadPoolExecutor(int corePoolSize,                              int maximumPoolSize,                              long keepAliveTime,                              TimeUnit unit,                              BlockingQueue&lt;Runnable&gt; workQueue,                              ThreadFactory threadFactory,                              RejectedExecutionHandler handler)corePoolSize:线程池中的核心线程数,即使没有任务执行的时候,他们也是存在的.(不考虑配置了参数:allowCoreThreadTimeOut,allowCoreThreadTimeOut通过字面意思也能知道,就是是否允许核心线程超时,一般情况下不需要设置,本文不考虑)maximumPoolSize:线程池中的允许存在的最大线程数keepAliveTime:当线程池中的线程超过核心线程数的时候,这部分多余的空闲线程等待执行新任务的超时时间.例如:核心线程数为1 ,最大线程数为5,当前运行线程为4,keepAliveTime为60s,那么4-1=3个线程在空闲状态下等待60s 后还没有新任务到来,就会被销毁了.unit:keepAliveTime 的时间单位workQueue: 线程队列,如果当前时间核心线程都在运行,又来了一个新任务,那么这个新任务就会被放进这个线程队列中,等待执行.threadFactory: 线程池创建线程的工厂类.handler: 如果线程队列满了同事执行线程数也达到了maximumPoolSize,如果此时再来新的线程,将执行什么 handler 来处理这个线程. handler的默认提供的类型有:AbortPolicy: 抛出RejectedExecutionException异常DiscardPolicy: 什么都不做.DiscardOldestPolicy: 将线程队列中的最老的任务抛弃掉,换区一个空间执行当前的任务.CallerRunsPolicy: 使用当前的线程(比如 main)来执行这个线程.JDK线程创建回收策略&lt;corePoolSize:如果新加入一个运行的任务,当前运行的线程小于corePoolSize,这时候会在线程池中新建一个线程用于执行这个新的任务.&gt;corePoolSize,队列不满:如果新加入一个运行的任务,当前运行的线程大于等于corePoolSize,这个时候就需要将这个新的任务加入到线程队列workQueue中,一旦线程中的线程执行完成了一个任务,就会马上从队列中去一个任务来执行.&gt;corePoolSize,&lt;maximumPoolSize:如果队列也满了,怎么办呢? 如果maximumPoolSize大于corePoolSize,就会新建线程来处理这个新的任务,直到总运行线程数达到maximumPoolSize.&gt;maximumPoolSize:如果总运行线程数达到了maximumPoolSize,还来了新的任务怎么办呢?就需要执行上面所说的拒绝策略了handler了,按照配置的策略进行处理,默认不配置的情况下,使用的是AbortPolicy.keepAliveTime:超过corePoolSize的线程，在空闲时间超过keepAliveTime时会被释放allowCoreThreadTimeOut:在配置了allowCoreThreadTimeOut时，corePoolSize线程在空闲时也会释放，一般不配置。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/pexelsphoto1040161.jpeg","plink":"https://snailscoder.com/2020/04/11/architect/intro-04/"},{"title":"高并发系统：系统可用性的度量","date":"2020-04-11T19:39:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:03:30.519Z","content":"衡量指标可用性是一个抽象的概念，你需要知道要如何来度量它，与之相关的概念是：MTBF 和 MTTR。\nMTBF（Mean Time Between Failure） 是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。\nMTTR（Mean Time To Repair）表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。\n系统可用性指标： Availability = MTBF / (MTBF + MTTR)这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。\n三个九之后，系统的年故障时间从 3 天锐减到 8 小时。四个九之后，年故障时间缩减到 1 小时之内。在这个级别的可用性下，你可能需要建立完善的运维值班体系、故障处理流程和业务变更流程。你可能还需要在系统设计上有更多的考虑。比如，在开发中你要考虑，如果发生故障，是否不用人工介入就能自动恢复。当然了，在工具建设方面，你也需要多加完善，以便快速排查故障原因，让系统快速恢复。五个九之后，故障就不能靠人力恢复了。想象一下，从故障发生到你接收报警，再到你打开电脑登录服务器处理问题，时间可能早就过了十分钟了。所以这个级别的可用性考察的是系统的容灾和自动恢复的能力，让机器来处理故障，才会让可用性指标提升一个档次。设计思路系统设计failover（故障转移）心跳监测，故障转移超时控制通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的，然后依据这个时间来指定超时时间降级降级是为了保证核心服务的稳定而牺牲非核心服务的做法。限流通过对并发的请求进行限速来保护系统系统运维灰度发布灰度发布指的是系统的变更不是一次性地推到线上的，而是按照一定比例逐步推进的。故障演练故障演练指的是对系统进行一些破坏性的手段，观察在出现局部故障时，整体的系统表现是怎样的，从而发现系统中存在的，潜在的可用性问题。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/1.png","plink":"https://snailscoder.com/2020/04/11/architect/intro-03/"},{"title":"高并发系统：经典分层举例","date":"2020-04-11T17:39:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:03:30.526Z","content":"1.应用三层架构\n表现层：顾名思义嘛，就是展示数据结果和接受用户指令的，是最靠近用户的一层；逻辑层：里面有复杂业务的具体实现；数据访问层则：是主要处理和存储之间的交互。\n2.网络分层架构\nOSI 网络模型，它把整个网络分成了七层，自下而上分别是物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。TCP/IP 协议，它把网络简化成了四层，即链路层、网络层、传输层和应用层。每一层各司其职又互相帮助，网络层负责端到端的寻址和建立连接，传输层负责端到端的数据传输等，同时相邻两层还会有数据的交互。这样可以隔离关注点，让不同的层专注做不同的事情。\n3.Linux文件系统分层\n在文件系统的最上层是虚拟文件系统（VFS），用来屏蔽不同的文件系统之间的差异，提供统一的系统调用接口。虚拟文件系统的下层是 Ext3、Ext4 等各种文件系统，再向下是为了屏蔽不同硬件设备的实现细节，我们抽象出来的单独的一层——通用块设备层，然后就是不同类型的磁盘了。\n\n4.阿里系统分层规约\n终端显示层：各端模板渲染并执行显示的层。当前主要是 Velocity 渲染，JS 渲染， JSP 渲染，移动端展示等。开放接口层：将 Service 层方法封装成开放接口，同时进行网关安全控制和流量控制等。Web 层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。Service 层：业务逻辑层。Manager 层：通用业务处理层。这一层主要有两个作用，其一，你可以将原先 Service 层的一些通用能力下沉到这一层，比如与缓存和存储交互策略，中间件的接入；其二，你也可以在这一层封装对第三方接口的调用，比如调用支付服务，调用审核服务等。DAO 层：数据访问层，与底层 MySQL、Oracle、HBase 等进行数据交互。外部接口或第三方平台：包括其它部门 RPC 开放接口，基础平台，其它公司的 HTTP 接口。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/haibian.jpg","plink":"https://snailscoder.com/2020/04/11/architect/intro-02/"},{"title":"高并发系统：通用设计方法","date":"2020-04-11T16:56:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T02:51:20.404Z","content":"洪水猛兽通常如何治理洪水，方案如下：\n分流：将水分流到多个支流中，以分担水流压力提高流速： 拓宽河道，清除淤沙让流水更加顺畅水库：将水引入水库先存储起来，然后再想办法把水库中的水缓缓地排出去，以此提高下游的抗洪能力高并发高并发就像洪水猛兽，处理方案类似：\n横向扩展：分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击。异步：在某些场景下，未处理完成之前我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。\n方案一：Scale-out（横向扩展）系统分布式设计，横向扩展，增加节点。微服务：SpringCloud\n方案二：缓存为什么使用缓存？普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都是在 ns（纳秒）级别，从千兆网卡上读取数据的时间是在μs（微秒）级别。所以在整个计算机体系中磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此我们通常使用以内存作为存储介质的缓存，以此提升性能。Redis\n方案三：异步调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。Reactive三方消息：RabbitMQ，Kafka，RocketMQ，ActiveMQ等\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/01/img1276.png","plink":"https://snailscoder.com/2020/04/11/architect/Intro-01/"},{"title":"学会承受人生必然的孤独，过了才能看见美好繁华！","date":"2020-04-03T16:38:25.000Z","date_formatted":{"ll":"2020年4月3日","L":"2020/04/03","MM-DD":"04-03"},"updated":"2020-04-12T04:23:27.157Z","content":"人生语录：学会承受人生必然的孤独，过了才能看见美好繁华！\n分享一段特别好的话：“爱好，是可以救命的”，当你人生迷茫困惑的时候，不要停下来，去做你喜欢的事情，忙碌起来，改变心境，你会逐渐发现，一切居然豁然开朗起来…生活中有很多不容易，却阻挡不了任何一个热爱生活的人去散发光芒。\n身边朋友纵然很多，但如若没有合拍的，在一起时内心想必也是孤独的。不合无意义的群。孤独虽然如影随形，但不必惧怕它，它是你生活中不可或缺的一部分，试着与它相处吧。孤独不是贬义词，当一个人的时候，可以思考自己的事情，欣赏喜欢的电影。或者培养一个爱好吧，也许在喜欢的领域里会交到更合拍的朋友。耐得住寂寞，才能享的了长远。\n真正想要的东西，不只是踮踮脚尖那么简单，所有的收获，一定要全力以赴，奋不顾身。 人生没有多走的路，脚下的每一步都算数。没有不请自来的幸运，只有有备而来的惊艳。没有人能定义你的未来，除了你自己。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/gudu.png","plink":"https://snailscoder.com/2020/04/03/notes/2020-04-03/"},{"title":"东小口森林公园-花朵","date":"2020-04-02T17:51:00.000Z","date_formatted":{"ll":"2020年4月2日","L":"2020/04/02","MM-DD":"04-02"},"updated":"2020-04-12T04:16:36.817Z","content":"裁剪前\n裁剪后\n自行车，拍的很不好看。水平欠佳\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/01/dsc0346.jpg","plink":"https://snailscoder.com/2020/04/02/travel/dxk/"},{"title":"个人博客Nginx强制跳转Https配置","date":"2020-04-01T19:38:25.000Z","date_formatted":{"ll":"2020年4月1日","L":"2020/04/01","MM-DD":"04-01"},"updated":"2020-04-01T12:25:46.588Z","content":"今日因需要将自己的博客域名加入https支持，并把之前的HTTP访问强制跳转到HTTPS。\n1、nginx支持https如果起初nginx编译时没有添加ssl支持，需要对nginx重新编译，增加http_ssl_module模块\n12345671.配置.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --with-http_stub_status_module --with-http_ssl_module2.编译安装make &amp;&amp; make install2、配置https域及SSL证书没有证书的可以考虑腾讯云申请免费证书，但仅限单域名,申请地址:https://cloud.tencent.com/product/ssl,申请通过后，下载nginx专用证书。以下为https证书相关配置\n123456789101112server &#123;    listen       443 ssl;    server_name  www.snailscoder.com;    ssl_certificate      ..&#x2F;ssl&#x2F;***.crt;    ssl_certificate_key  ..&#x2F;ssl&#x2F;***.key;    ssl_session_cache    shared:SSL:1m;    ssl_session_timeout  5m;    location &#x2F; &#123;        root   html;        index  index.html index.htm;    &#125;&#125;配置好后，测试https是否可以正常访问。\n3、http强制跳转https此处因http下无其他信息，单纯配置了跳转\n12345678910server &#123;    listen       80;    server_name  www.snailscoder.com;    #方式一    return      301 https:&#x2F;&#x2F;$server_name$request_uri;    #方式二    #rewrite ^&#x2F;(.*)$ https:&#x2F;&#x2F;www.snailscoder.com&#x2F;$1 permanent;    #方式三    #rewrite ^ https:&#x2F;&#x2F;www.snailscoder.com$request_uri? permanent;&#125;博客内容较简单，仅为个人配置记录，有问题可留言咨询。有更好的方案，也请多多指教。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/01/img1276.png","plink":"https://snailscoder.com/2020/04/01/http/nginx-rewrite/"},{"title":"Java虚拟机总结思维导图","date":"2020-04-01T19:38:25.000Z","date_formatted":{"ll":"2020年4月1日","L":"2020/04/01","MM-DD":"04-01"},"updated":"2020-04-01T12:24:41.066Z","content":"\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/01/wnlpc.png","plink":"https://snailscoder.com/2020/04/01/java/100001/"},{"title":"闲逛景山","date":"2020-03-31T21:51:00.000Z","date_formatted":{"ll":"2020年3月31日","L":"2020/03/31","MM-DD":"03-31"},"updated":"2020-04-12T04:16:36.854Z","content":"盛开的梅花\n远望故宫博物院\n园中肥野猫\n寂静的街头\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/31/dsc0562.jpg","plink":"https://snailscoder.com/2020/03/31/travel/jingshan/"},{"title":"Java中flag和flag==true的区别","date":"2020-03-21T21:56:25.000Z","date_formatted":{"ll":"2020年3月21日","L":"2020/03/21","MM-DD":"03-21"},"updated":"2020-04-01T12:24:46.477Z","content":"有如下 Test.java 文件\n123456789public class Test &#123;     public static void main(String[] args) &#123;          boolean flag &#x3D; true;          if (flag)             System.out.println(&quot;Hello, Java!&quot;);          if (flag &#x3D;&#x3D; true)                   System.out.println(&quot;Hello, JVM!&quot;);     &#125;&#125;此处 flag和flag == true大家认为有区别吗？\n下边让我们来见证一下奇迹:\njavac Foo.java 命令生成 Foo.class 文件，使用 JD-GUI 打开内容如下：\n123456789101112131415import java.io.PrintStream;public class Foo&#123;  public static void main(String[] paramArrayOfString)  &#123;    int i &#x3D; 1;    if (i !&#x3D; 0) &#123;      System.out.println(&quot;Hello, Java!&quot;);    &#125;    if (i &#x3D;&#x3D; 1) &#123;      System.out.println(&quot;Hello, JVM!&quot;);    &#125;  &#125;&#125;大家看到不同之处了吗？\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/21/9a15a3bb8de2b97650bf14ff310e39ac.jpg","plink":"https://snailscoder.com/2020/03/21/java/100000/"},{"title":"北海公园之游","date":"2020-03-21T11:56:25.000Z","date_formatted":{"ll":"2020年3月21日","L":"2020/03/21","MM-DD":"03-21"},"updated":"2020-04-12T04:16:36.845Z","content":"\n\n\n\n\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/31/bh20200320.jpg","plink":"https://snailscoder.com/2020/03/21/travel/beihai/"},{"title":"一条SQL查询语句是如何执行的","date":"2020-03-20T21:56:25.000Z","date_formatted":{"ll":"2020年3月20日","L":"2020/03/20","MM-DD":"03-20"},"updated":"2020-04-12T03:17:36.932Z","content":"\nMySQL 的逻辑架构图\n连接器查询缓存分析器优化器执行器","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/31/38dd4b12f16d2f9667fb169be0f0698b.jpg","plink":"https://snailscoder.com/2020/03/20/mysql/select-run/"},{"title":"疫情下的颐和园","date":"2020-03-20T10:56:25.000Z","date_formatted":{"ll":"2020年3月20日","L":"2020/03/20","MM-DD":"03-20"},"updated":"2020-04-12T04:16:35.273Z","content":"疫情期间的颐和园，人烟稀少，却是风光无限，沉淀出了时光的痕迹。择一日，春光曼妙，风和日丽，漫步园中，岁月静好。\n园内风景十七孔桥\n远观玉峰塔\n清净的湖面，风景美不胜收\n盛开的山桃花\n远眺佛香阁\n再现十七孔桥\n零星的观景人\n昔日吵闹的长廊\n阳春三月，昔日人流如织，如今….\n没有游船，只有野鸭、黑天鹅;没有商店，没有泡面、火腿;\n人烟稀少，却是风光无限。\n希望疫情早点结束…\n入园攻略提前一天“颐和园”官方微信公众号进行预约购票，可预约上午、下午两个时段，不预约不能进。第二天直接刷身份证入园（一定要带身份证！！）疫情期间只有新建宫门开放，其他都是关闭的。开车前往的旁边有6-7号停车场，方便停车。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/20/shi-qi-kong-qiao.jpg","plink":"https://snailscoder.com/2020/03/20/travel/yhy/"},{"title":"关于’蜗码‘","date":"2020-04-12T12:32:22.880Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-02T03:31:31.343Z","content":"博客来由我们每个人的在网络上产生的数据越来越多，这些信息是我们在互联网上存在过的痕迹，值得我们认真对待。但是它们被分散分布在各个网站上。很多时候我们很难将它们聚合在一起，而且各个网站的信息排布方式也没有办法自由控制，所以我们需要一个可以由自己主宰的空间——博客。\n通过博客，我们可以记录自己的生活和成长的轨迹。它不像 Twitter 那样碎片化，也不像 Facebook 那样关系化，它是私人的空间。\n关于’蜗码‘蜗牛，一步一个脚印的向自己的目标爬行.蜗码，像蜗牛一样的码农，让自己像蜗牛一样，踏踏实实的进步，不再浮躁。\n博客平台博客： Hexo部署： GitHub Pages主题： inside评论： Gitalk\n","plink":"https://snailscoder.com/about/"}]