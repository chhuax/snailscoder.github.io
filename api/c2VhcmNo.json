[{"title":"LinkedList源码解析","date":"2020-04-21T21:32:00.000Z","date_formatted":{"ll":"2020年4月21日","L":"2020/04/21","MM-DD":"04-21"},"updated":"2020-04-21T13:41:34.392Z","content":"简介内部结构分析LinkedList源码分析构造方法添加（add）方法根据位置取数据的方法根据对象得到索引的方法检查链表是否包含某对象的方法：删除（remove/pop）方法LinkedList类常用方法测试：简介LinkedList是一个实现了List接口和Deque接口的双端链表。LinkedList底层的链表结构使它支持高效的插入和删除操作，另外它实现了Deque接口，使得LinkedList类也具有队列的特性;LinkedList不是线程安全的，如果想使LinkedList变成线程安全的，可以调用静态类Collections类中的synchronizedList方法： \n1List list=Collections.synchronizedList(new LinkedList(...));内部结构分析如下图所示：\n看完了图之后，我们再看LinkedList类中的一个内部私有类Node就很好理解了：\n1234567891011private static class Node&lt;E&gt; &#123;        E item;//节点值        Node&lt;E&gt; next;//后继节点        Node&lt;E&gt; prev;//前驱节点        Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123;            this.item = element;            this.next = next;            this.prev = prev;        &#125;    &#125;这个类就代表双端链表的节点Node。这个类有三个属性，分别是前驱节点，本节点的值，后继结点。\nLinkedList源码分析构造方法空构造方法：\n12public LinkedList() &#123;&#125;用已有的集合创建链表的构造方法：\n1234public LinkedList(Collection&lt;? extends E&gt; c) &#123;    this();    addAll(c);&#125;add方法add(E e) 方法：将元素添加到链表尾部\n1234public boolean add(E e) &#123;        linkLast(e);//这里就只调用了这一个方法        return true;    &#125;1234567891011121314/**  * 链接使e作为最后一个元素。  */ void linkLast(E e) &#123;     final Node&lt;E&gt; l = last;     final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null);     last = newNode;//新建节点     if (l == null)         first = newNode;     else         l.next = newNode;//指向后继元素也就是指向下一个元素     size++;     modCount++; &#125;add(int index,E e)：在指定位置添加元素\n12345678public void add(int index, E element) &#123;        checkPositionIndex(index); //检查索引是否处于[0-size]之间        if (index == size)//添加在链表尾部            linkLast(element);        else//添加在链表中间            linkBefore(element, node(index));    &#125;linkBefore方法需要给定两个参数，一个插入节点的值，一个指定的node，所以我们又调用了Node(index)去找到index对应的node\naddAll(Collection  c )：将集合插入到链表尾部\n123public boolean addAll(Collection&lt;? extends E&gt; c) &#123;        return addAll(size, c);    &#125;addAll(int index, Collection c)： 将集合从指定位置开始插入\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;        //1:检查index范围是否在size之内        checkPositionIndex(index);        //2:toArray()方法把集合的数据存到对象数组中        Object[] a = c.toArray();        int numNew = a.length;        if (numNew == 0)            return false;        //3：得到插入位置的前驱节点和后继节点        Node&lt;E&gt; pred, succ;        //如果插入位置为尾部，前驱节点为last，后继节点为null        if (index == size) &#123;            succ = null;            pred = last;        &#125;        //否则，调用node()方法得到后继节点，再得到前驱节点        else &#123;            succ = node(index);            pred = succ.prev;        &#125;        // 4：遍历数据将数据插入        for (Object o : a) &#123;            @SuppressWarnings(\"unchecked\") E e = (E) o;            //创建新节点            Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null);            //如果插入位置在链表头部            if (pred == null)                first = newNode;            else                pred.next = newNode;            pred = newNode;        &#125;        //如果插入位置在尾部，重置last节点        if (succ == null) &#123;            last = pred;        &#125;        //否则，将插入的链表与先前链表连接起来        else &#123;            pred.next = succ;            succ.prev = pred;        &#125;        size += numNew;        modCount++;        return true;    &#125;上面可以看出addAll方法通常包括下面四个步骤：\n检查index范围是否在size之内toArray()方法把集合的数据存到对象数组中得到插入位置的前驱和后继节点遍历数据，将数据插入到指定位置addFirst(E e)： 将元素添加到链表头部\n123public void addFirst(E e) &#123;       linkFirst(e);   &#125;12345678910111213private void linkFirst(E e) &#123;        final Node&lt;E&gt; f = first;        final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f);//新建节点，以头节点为后继节点        first = newNode;        //如果链表为空，last节点也指向该节点        if (f == null)            last = newNode;        //否则，将头节点的前驱指针指向新节点，也就是指向前一个元素        else            f.prev = newNode;        size++;        modCount++;    &#125;addLast(E e)： 将元素添加到链表尾部，与 add(E e) 方法一样\n123public void addLast(E e) &#123;        linkLast(e);    &#125;根据位置取数据的方法get(int index)： 根据指定索引返回数据\n123456public E get(int index) &#123;        //检查index范围是否在size之内        checkElementIndex(index);        //调用Node(index)去找到index对应的node然后返回它的值        return node(index).item;    &#125;获取头节点（index=0）数据方法:\n123456789101112131415161718public E getFirst() &#123;        final Node&lt;E&gt; f = first;        if (f == null)            throw new NoSuchElementException();        return f.item;    &#125;public E element() &#123;        return getFirst();    &#125;public E peek() &#123;        final Node&lt;E&gt; f = first;        return (f == null) ? null : f.item;    &#125;public E peekFirst() &#123;        final Node&lt;E&gt; f = first;        return (f == null) ? null : f.item;     &#125;区别：getFirst(),element(),peek(),peekFirst()这四个获取头结点方法的区别在于对链表为空时的处理，是抛出异常还是返回null，其中getFirst() 和element() 方法将会在链表为空时，抛出异常\nelement()方法的内部就是使用getFirst()实现的。它们会在链表为空时，抛出NoSuchElementException获取尾节点（index=-1）数据方法:\n12345678910public E getLast() &#123;       final Node&lt;E&gt; l = last;       if (l == null)           throw new NoSuchElementException();       return l.item;   &#125;public E peekLast() &#123;       final Node&lt;E&gt; l = last;       return (l == null) ? null : l.item;   &#125;两者区别：getLast() 方法在链表为空时，会抛出NoSuchElementException，而peekLast() 则不会，只是会返回 null。\n根据对象得到索引的方法int indexOf(Object o)： 从头遍历找\n12345678910111213141516171819public int indexOf(Object o) &#123;        int index = 0;        if (o == null) &#123;            //从头遍历            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                if (x.item == null)                    return index;                index++;            &#125;        &#125; else &#123;            //从头遍历            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                if (o.equals(x.item))                    return index;                index++;            &#125;        &#125;        return -1;    &#125;int lastIndexOf(Object o)： 从尾遍历找\n12345678910111213141516171819public int lastIndexOf(Object o) &#123;        int index = size;        if (o == null) &#123;            //从尾遍历            for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123;                index--;                if (x.item == null)                    return index;            &#125;        &#125; else &#123;            //从尾遍历            for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123;                index--;                if (o.equals(x.item))                    return index;            &#125;        &#125;        return -1;    &#125;检查链表是否包含某对象的方法：contains(Object o)： 检查对象o是否存在于链表中\n123public boolean contains(Object o) &#123;       return indexOf(o) != -1;   &#125;删除方法remove() ,removeFirst(),pop(): 删除头节点\n123456789101112public E pop() &#123;        return removeFirst();    &#125;public E remove() &#123;        return removeFirst();    &#125;public E removeFirst() &#123;        final Node&lt;E&gt; f &#x3D; first;        if (f &#x3D;&#x3D; null)            throw new NoSuchElementException();        return unlinkFirst(f);    &#125;removeLast(),pollLast(): 删除尾节点\n12345678910public E removeLast() &#123;        final Node&lt;E&gt; l = last;        if (l == null)            throw new NoSuchElementException();        return unlinkLast(l);    &#125;public E pollLast() &#123;        final Node&lt;E&gt; l = last;        return (l == null) ? null : unlinkLast(l);    &#125;区别： removeLast()在链表为空时将抛出NoSuchElementException，而pollLast()方法返回null。\nremove(Object o): 删除指定元素\n12345678910111213141516171819202122232425public boolean remove(Object o) &#123;        //如果删除对象为null        if (o == null) &#123;            //从头开始遍历            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                //找到元素                if (x.item == null) &#123;                   //从链表中移除找到的元素                    unlink(x);                    return true;                &#125;            &#125;        &#125; else &#123;            //从头开始遍历            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                //找到元素                if (o.equals(x.item)) &#123;                    //从链表中移除找到的元素                    unlink(x);                    return true;                &#125;            &#125;        &#125;        return false;    &#125;当删除指定对象时，只需调用remove(Object o)即可，不过该方法一次只会删除一个匹配的对象，如果删除了匹配对象，返回true，否则false。\nunlink(Node x) 方法：\n123456789101112131415161718192021222324252627E unlink(Node&lt;E&gt; x) &#123;        // assert x != null;        final E element = x.item;        final Node&lt;E&gt; next = x.next;//得到后继节点        final Node&lt;E&gt; prev = x.prev;//得到前驱节点        //删除前驱指针        if (prev == null) &#123;            first = next;//如果删除的节点是头节点,令头节点指向该节点的后继节点        &#125; else &#123;            prev.next = next;//将前驱节点的后继节点指向后继节点            x.prev = null;        &#125;        //删除后继指针        if (next == null) &#123;            last = prev;//如果删除的节点是尾节点,令尾节点指向该节点的前驱节点        &#125; else &#123;            next.prev = prev;            x.next = null;        &#125;        x.item = null;        size--;        modCount++;        return element;    &#125;remove(int index)：删除指定位置的元素\n123456public E remove(int index) &#123;        //检查index范围        checkElementIndex(index);        //将节点删除        return unlink(node(index));    &#125;LinkedList类常用方法测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package list;import java.util.Iterator;import java.util.LinkedList;public class LinkedListDemo &#123;    public static void main(String[] srgs) &#123;        //创建存放int类型的linkedList        LinkedList&lt;Integer&gt; linkedList = new LinkedList&lt;&gt;();        /************************** linkedList的基本操作 ************************/        linkedList.addFirst(0); // 添加元素到列表开头        linkedList.add(1); // 在列表结尾添加元素        linkedList.add(2, 2); // 在指定位置添加元素        linkedList.addLast(3); // 添加元素到列表结尾                System.out.println(\"LinkedList（直接输出的）: \" + linkedList);        System.out.println(\"getFirst()获得第一个元素: \" + linkedList.getFirst()); // 返回此列表的第一个元素        System.out.println(\"getLast()获得第最后一个元素: \" + linkedList.getLast()); // 返回此列表的最后一个元素        System.out.println(\"removeFirst()删除第一个元素并返回: \" + linkedList.removeFirst()); // 移除并返回此列表的第一个元素        System.out.println(\"removeLast()删除最后一个元素并返回: \" + linkedList.removeLast()); // 移除并返回此列表的最后一个元素        System.out.println(\"After remove:\" + linkedList);        System.out.println(\"contains()方法判断列表是否包含1这个元素:\" + linkedList.contains(1)); // 判断此列表包含指定元素，如果是，则返回true        System.out.println(\"该linkedList的大小 : \" + linkedList.size()); // 返回此列表的元素个数        /************************** 位置访问操作 ************************/        System.out.println(\"-----------------------------------------\");        linkedList.set(1, 3); // 将此列表中指定位置的元素替换为指定的元素        System.out.println(\"After set(1, 3):\" + linkedList);        System.out.println(\"get(1)获得指定位置（这里为1）的元素: \" + linkedList.get(1)); // 返回此列表中指定位置处的元素        /************************** Search操作 ************************/        System.out.println(\"-----------------------------------------\");        linkedList.add(3);        System.out.println(\"indexOf(3): \" + linkedList.indexOf(3)); // 返回此列表中首次出现的指定元素的索引        System.out.println(\"lastIndexOf(3): \" + linkedList.lastIndexOf(3));// 返回此列表中最后出现的指定元素的索引        /************************** Queue操作 ************************/        System.out.println(\"-----------------------------------------\");        System.out.println(\"peek(): \" + linkedList.peek()); // 获取但不移除此列表的头        System.out.println(\"element(): \" + linkedList.element()); // 获取但不移除此列表的头        linkedList.poll(); // 获取并移除此列表的头        System.out.println(\"After poll():\" + linkedList);        linkedList.remove();        System.out.println(\"After remove():\" + linkedList); // 获取并移除此列表的头        linkedList.offer(4);        System.out.println(\"After offer(4):\" + linkedList); // 将指定元素添加到此列表的末尾        /************************** Deque操作 ************************/        System.out.println(\"-----------------------------------------\");        linkedList.offerFirst(2); // 在此列表的开头插入指定的元素        System.out.println(\"After offerFirst(2):\" + linkedList);        linkedList.offerLast(5); // 在此列表末尾插入指定的元素        System.out.println(\"After offerLast(5):\" + linkedList);        System.out.println(\"peekFirst(): \" + linkedList.peekFirst()); // 获取但不移除此列表的第一个元素        System.out.println(\"peekLast(): \" + linkedList.peekLast()); // 获取但不移除此列表的第一个元素        linkedList.pollFirst(); // 获取并移除此列表的第一个元素        System.out.println(\"After pollFirst():\" + linkedList);        linkedList.pollLast(); // 获取并移除此列表的最后一个元素        System.out.println(\"After pollLast():\" + linkedList);        linkedList.push(2); // 将元素推入此列表所表示的堆栈（插入到列表的头）        System.out.println(\"After push(2):\" + linkedList);        linkedList.pop(); // 从此列表所表示的堆栈处弹出一个元素（获取并移除列表第一个元素）        System.out.println(\"After pop():\" + linkedList);        linkedList.add(3);        linkedList.removeFirstOccurrence(3); // 从此列表中移除第一次出现的指定元素（从头部到尾部遍历列表）        System.out.println(\"After removeFirstOccurrence(3):\" + linkedList);        linkedList.removeLastOccurrence(3); // 从此列表中移除最后一次出现的指定元素（从尾部到头部遍历列表）        System.out.println(\"After removeFirstOccurrence(3):\" + linkedList);        /************************** 遍历操作 ************************/        System.out.println(\"-----------------------------------------\");        linkedList.clear();        for (int i = 0; i &lt; 100000; i++) &#123;            linkedList.add(i);        &#125;        // 迭代器遍历        long start = System.currentTimeMillis();        Iterator&lt;Integer&gt; iterator = linkedList.iterator();        while (iterator.hasNext()) &#123;            iterator.next();        &#125;        long end = System.currentTimeMillis();        System.out.println(\"Iterator：\" + (end - start) + \" ms\");        // 顺序遍历(随机遍历)        start = System.currentTimeMillis();        for (int i = 0; i &lt; linkedList.size(); i++) &#123;            linkedList.get(i);        &#125;        end = System.currentTimeMillis();        System.out.println(\"for：\" + (end - start) + \" ms\");        // 另一种for循环遍历        start = System.currentTimeMillis();        for (Integer i : linkedList)            ;        end = System.currentTimeMillis();        System.out.println(\"for2：\" + (end - start) + \" ms\");        // 通过pollFirst()或pollLast()来遍历LinkedList        LinkedList&lt;Integer&gt; temp1 = new LinkedList&lt;&gt;();        temp1.addAll(linkedList);        start = System.currentTimeMillis();        while (temp1.size() != 0) &#123;            temp1.pollFirst();        &#125;        end = System.currentTimeMillis();        System.out.println(\"pollFirst()或pollLast()：\" + (end - start) + \" ms\");        // 通过removeFirst()或removeLast()来遍历LinkedList        LinkedList&lt;Integer&gt; temp2 = new LinkedList&lt;&gt;();        temp2.addAll(linkedList);        start = System.currentTimeMillis();        while (temp2.size() != 0) &#123;            temp2.removeFirst();        &#125;        end = System.currentTimeMillis();        System.out.println(\"removeFirst()或removeLast()：\" + (end - start) + \" ms\");    &#125;&#125;","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/21/399161.jpg","plink":"https://snailscoder.com/2020/04/21/java/linkedlist/"},{"title":"ArrayList源码解析","date":"2020-04-21T19:23:00.000Z","date_formatted":{"ll":"2020年4月21日","L":"2020/04/21","MM-DD":"04-21"},"updated":"2020-04-21T13:34:21.019Z","content":"ArrayList简介ArrayList核心源码ArrayList源码分析System.arraycopy()和Arrays.copyOf()方法两者联系与区别ArrayList核心扩容技术内部类ArrayList经典DemoArrayList简介　　ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。\n   它继承于 AbstractList，实现了 List, RandomAccess, Cloneable, java.io.Serializable 这些接口。\n   在我们学数据结构的时候就知道了线性表的顺序存储，插入删除元素的时间复杂度为O（n）,求表长以及增加元素，取第 i   元素的时间复杂度为O（1）\n　  ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。\n　　ArrayList 实现了RandomAccess 接口， RandomAccess 是一个标志接口，表明实现这个这个接口的 List 集合是支持快速随机访问的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。\n　　ArrayList 实现了Cloneable 接口，即覆盖了函数 clone()，能被克隆。\n　　ArrayList 实现java.io.Serializable 接口，这意味着ArrayList支持序列化，能通过序列化去传输。\n　　和 Vector 不同，ArrayList 中的操作不是线程安全的！所以，建议在单线程中才使用 ArrayList，而在多线程中可以选择 Vector 或者  CopyOnWriteArrayList。\nArrayList核心源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498package java.util;import java.util.function.Consumer;import java.util.function.Predicate;import java.util.function.UnaryOperator;public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123;    private static final long serialVersionUID = 8683452581122892189L;    /**     * 默认初始容量大小     */    private static final int DEFAULT_CAPACITY = 10;    /**     * 空数组（用于空实例）。     */    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;     //用于默认大小空实例的共享空数组实例。      //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;    /**     * 保存ArrayList数据的数组     */    transient Object[] elementData; // non-private to simplify nested class access    /**     * ArrayList 所包含的元素个数     */    private int size;    /**     * 带初始容量参数的构造函数。（用户自己指定容量）     */    public ArrayList(int initialCapacity) &#123;        if (initialCapacity &gt; 0) &#123;            //创建initialCapacity大小的数组            this.elementData = new Object[initialCapacity];        &#125; else if (initialCapacity == 0) &#123;            //创建空数组            this.elementData = EMPTY_ELEMENTDATA;        &#125; else &#123;            throw new IllegalArgumentException(\"Illegal Capacity: \"+                                               initialCapacity);        &#125;    &#125;    /**     *默认构造函数，DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0.初始化为10，也就是说初始其实是空数组 当添加第一个元素的时候数组容量才变成10     */    public ArrayList() &#123;        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;    &#125;    /**     * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。     */    public ArrayList(Collection&lt;? extends E&gt; c) &#123;        //        elementData = c.toArray();        //如果指定集合元素个数不为0        if ((size = elementData.length) != 0) &#123;            // c.toArray 可能返回的不是Object类型的数组所以加上下面的语句用于判断，            //这里用到了反射里面的getClass()方法            if (elementData.getClass() != Object[].class)                elementData = Arrays.copyOf(elementData, size, Object[].class);        &#125; else &#123;            // 用空数组代替            this.elementData = EMPTY_ELEMENTDATA;        &#125;    &#125;    /**     * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。      */    public void trimToSize() &#123;        modCount++;        if (size &lt; elementData.length) &#123;            elementData = (size == 0)              ? EMPTY_ELEMENTDATA              : Arrays.copyOf(elementData, size);        &#125;    &#125;//下面是ArrayList的扩容机制//ArrayList的扩容机制提高了性能，如果每次只扩充一个，//那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。    /**     * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量     * @param   minCapacity   所需的最小容量     */    public void ensureCapacity(int minCapacity) &#123;        int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)            // any size if not default element table            ? 0            // larger than default for default empty table. It's already            // supposed to be at default size.            : DEFAULT_CAPACITY;        if (minCapacity &gt; minExpand) &#123;            ensureExplicitCapacity(minCapacity);        &#125;    &#125;   //得到最小扩容量    private void ensureCapacityInternal(int minCapacity) &#123;        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;              // 获取默认的容量和传入参数的较大值            minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);        &#125;        ensureExplicitCapacity(minCapacity);    &#125;  //判断是否需要扩容    private void ensureExplicitCapacity(int minCapacity) &#123;        modCount++;        // overflow-conscious code        if (minCapacity - elementData.length &gt; 0)            //调用grow方法进行扩容，调用此方法代表已经开始扩容了            grow(minCapacity);    &#125;    /**     * 要分配的最大数组大小     */    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;    /**     * ArrayList扩容的核心方法。     */    private void grow(int minCapacity) &#123;        // oldCapacity为旧容量，newCapacity为新容量        int oldCapacity = elementData.length;        //将oldCapacity 右移一位，其效果相当于oldCapacity /2，        //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，        int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);        //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，        if (newCapacity - minCapacity &lt; 0)            newCapacity = minCapacity;        //再检查新容量是否超出了ArrayList所定义的最大容量，        //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE，        //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。        if (newCapacity - MAX_ARRAY_SIZE &gt; 0)            newCapacity = hugeCapacity(minCapacity);        // minCapacity is usually close to size, so this is a win:        elementData = Arrays.copyOf(elementData, newCapacity);    &#125;    //比较minCapacity和 MAX_ARRAY_SIZE    private static int hugeCapacity(int minCapacity) &#123;        if (minCapacity &lt; 0) // overflow            throw new OutOfMemoryError();        return (minCapacity &gt; MAX_ARRAY_SIZE) ?            Integer.MAX_VALUE :            MAX_ARRAY_SIZE;    &#125;    /**     *返回此列表中的元素数。      */    public int size() &#123;        return size;    &#125;    /**     * 如果此列表不包含元素，则返回 true 。     */    public boolean isEmpty() &#123;        //注意=和==的区别        return size == 0;    &#125;    /**     * 如果此列表包含指定的元素，则返回true 。     */    public boolean contains(Object o) &#123;        //indexOf()方法：返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1         return indexOf(o) &gt;= 0;    &#125;    /**     *返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1      */    public int indexOf(Object o) &#123;        if (o == null) &#123;            for (int i = 0; i &lt; size; i++)                if (elementData[i]==null)                    return i;        &#125; else &#123;            for (int i = 0; i &lt; size; i++)                //equals()方法比较                if (o.equals(elementData[i]))                    return i;        &#125;        return -1;    &#125;    /**     * 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。.     */    public int lastIndexOf(Object o) &#123;        if (o == null) &#123;            for (int i = size-1; i &gt;= 0; i--)                if (elementData[i]==null)                    return i;        &#125; else &#123;            for (int i = size-1; i &gt;= 0; i--)                if (o.equals(elementData[i]))                    return i;        &#125;        return -1;    &#125;    /**     * 返回此ArrayList实例的浅拷贝。 （元素本身不被复制。）      */    public Object clone() &#123;        try &#123;            ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone();            //Arrays.copyOf功能是实现数组的复制，返回复制后的数组。参数是被复制的数组和复制的长度            v.elementData = Arrays.copyOf(elementData, size);            v.modCount = 0;            return v;        &#125; catch (CloneNotSupportedException e) &#123;            // 这不应该发生，因为我们是可以克隆的            throw new InternalError(e);        &#125;    &#125;    /**     *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。      *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。     *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。     */    public Object[] toArray() &#123;        return Arrays.copyOf(elementData, size);    &#125;    /**     * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）;      *返回的数组的运行时类型是指定数组的运行时类型。 如果列表适合指定的数组，则返回其中。      *否则，将为指定数组的运行时类型和此列表的大小分配一个新数组。      *如果列表适用于指定的数组，其余空间（即数组的列表数量多于此元素），则紧跟在集合结束后的数组中的元素设置为null 。     *（这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。）      */    @SuppressWarnings(\"unchecked\")    public &lt;T&gt; T[] toArray(T[] a) &#123;        if (a.length &lt; size)            // 新建一个运行时类型的数组，但是ArrayList数组的内容            return (T[]) Arrays.copyOf(elementData, size, a.getClass());            //调用System提供的arraycopy()方法实现数组之间的复制        System.arraycopy(elementData, 0, a, 0, size);        if (a.length &gt; size)            a[size] = null;        return a;    &#125;    // Positional Access Operations    @SuppressWarnings(\"unchecked\")    E elementData(int index) &#123;        return (E) elementData[index];    &#125;    /**     * 返回此列表中指定位置的元素。     */    public E get(int index) &#123;        rangeCheck(index);        return elementData(index);    &#125;    /**     * 用指定的元素替换此列表中指定位置的元素。      */    public E set(int index, E element) &#123;        //对index进行界限检查        rangeCheck(index);        E oldValue = elementData(index);        elementData[index] = element;        //返回原来在这个位置的元素        return oldValue;    &#125;    /**     * 将指定的元素追加到此列表的末尾。      */    public boolean add(E e) &#123;        ensureCapacityInternal(size + 1);  // Increments modCount!!        //这里看到ArrayList添加元素的实质就相当于为数组赋值        elementData[size++] = e;        return true;    &#125;    /**     * 在此列表中的指定位置插入指定的元素。      *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大；     *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。     */    public void add(int index, E element) &#123;        rangeCheckForAdd(index);        ensureCapacityInternal(size + 1);  // Increments modCount!!        //arraycopy()这个实现数组之间复制的方法一定要看一下，下面就用到了arraycopy()方法实现数组自己复制自己        System.arraycopy(elementData, index, elementData, index + 1,                         size - index);        elementData[index] = element;        size++;    &#125;    /**     * 删除该列表中指定位置的元素。 将任何后续元素移动到左侧（从其索引中减去一个元素）。      */    public E remove(int index) &#123;        rangeCheck(index);        modCount++;        E oldValue = elementData(index);        int numMoved = size - index - 1;        if (numMoved &gt; 0)            System.arraycopy(elementData, index+1, elementData, index,                             numMoved);        elementData[--size] = null; // clear to let GC do its work      //从列表中删除的元素         return oldValue;    &#125;    /**     * 从列表中删除指定元素的第一个出现（如果存在）。 如果列表不包含该元素，则它不会更改。     *返回true，如果此列表包含指定的元素     */    public boolean remove(Object o) &#123;        if (o == null) &#123;            for (int index = 0; index &lt; size; index++)                if (elementData[index] == null) &#123;                    fastRemove(index);                    return true;                &#125;        &#125; else &#123;            for (int index = 0; index &lt; size; index++)                if (o.equals(elementData[index])) &#123;                    fastRemove(index);                    return true;                &#125;        &#125;        return false;    &#125;    /*     * Private remove method that skips bounds checking and does not     * return the value removed.     */    private void fastRemove(int index) &#123;        modCount++;        int numMoved = size - index - 1;        if (numMoved &gt; 0)            System.arraycopy(elementData, index+1, elementData, index,                             numMoved);        elementData[--size] = null; // clear to let GC do its work    &#125;    /**     * 从列表中删除所有元素。      */    public void clear() &#123;        modCount++;        // 把数组中所有的元素的值设为null        for (int i = 0; i &lt; size; i++)            elementData[i] = null;        size = 0;    &#125;    /**     * 按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾。     */    public boolean addAll(Collection&lt;? extends E&gt; c) &#123;        Object[] a = c.toArray();        int numNew = a.length;        ensureCapacityInternal(size + numNew);  // Increments modCount        System.arraycopy(a, 0, elementData, size, numNew);        size += numNew;        return numNew != 0;    &#125;    /**     * 将指定集合中的所有元素插入到此列表中，从指定的位置开始。     */    public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;        rangeCheckForAdd(index);        Object[] a = c.toArray();        int numNew = a.length;        ensureCapacityInternal(size + numNew);  // Increments modCount        int numMoved = size - index;        if (numMoved &gt; 0)            System.arraycopy(elementData, index, elementData, index + numNew,                             numMoved);        System.arraycopy(a, 0, elementData, index, numNew);        size += numNew;        return numNew != 0;    &#125;    /**     * 从此列表中删除所有索引为fromIndex （含）和toIndex之间的元素。     *将任何后续元素移动到左侧（减少其索引）。     */    protected void removeRange(int fromIndex, int toIndex) &#123;        modCount++;        int numMoved = size - toIndex;        System.arraycopy(elementData, toIndex, elementData, fromIndex,                         numMoved);        // clear to let GC do its work        int newSize = size - (toIndex-fromIndex);        for (int i = newSize; i &lt; size; i++) &#123;            elementData[i] = null;        &#125;        size = newSize;    &#125;    /**     * 检查给定的索引是否在范围内。     */    private void rangeCheck(int index) &#123;        if (index &gt;= size)            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125;    /**     * add和addAll使用的rangeCheck的一个版本     */    private void rangeCheckForAdd(int index) &#123;        if (index &gt; size || index &lt; 0)            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125;    /**     * 返回IndexOutOfBoundsException细节信息     */    private String outOfBoundsMsg(int index) &#123;        return \"Index: \"+index+\", Size: \"+size;    &#125;    /**     * 从此列表中删除指定集合中包含的所有元素。      */    public boolean removeAll(Collection&lt;?&gt; c) &#123;        Objects.requireNonNull(c);        //如果此列表被修改则返回true        return batchRemove(c, false);    &#125;    /**     * 仅保留此列表中包含在指定集合中的元素。     *换句话说，从此列表中删除其中不包含在指定集合中的所有元素。      */    public boolean retainAll(Collection&lt;?&gt; c) &#123;        Objects.requireNonNull(c);        return batchRemove(c, true);    &#125;    /**     * 从列表中的指定位置开始，返回列表中的元素（按正确顺序）的列表迭代器。     *指定的索引表示初始调用将返回的第一个元素为next 。 初始调用previous将返回指定索引减1的元素。      *返回的列表迭代器是fail-fast 。      */    public ListIterator&lt;E&gt; listIterator(int index) &#123;        if (index &lt; 0 || index &gt; size)            throw new IndexOutOfBoundsException(\"Index: \"+index);        return new ListItr(index);    &#125;    /**     *返回列表中的列表迭代器（按适当的顺序）。      *返回的列表迭代器是fail-fast 。     */    public ListIterator&lt;E&gt; listIterator() &#123;        return new ListItr(0);    &#125;    /**     *以正确的顺序返回该列表中的元素的迭代器。      *返回的迭代器是fail-fast 。      */    public Iterator&lt;E&gt; iterator() &#123;        return new Itr();    &#125;ArrayList源码分析System.arraycopy()和Arrays.copyOf()方法　　通过上面源码我们发现这两个实现数组复制的方法被广泛使用而且很多地方都特别巧妙。比如下面add(int index, E element)方法就很巧妙的用到了arraycopy()方法让数组自己复制自己实现让index开始之后的所有成员后移一个位置:\n123456789101112131415/** * 在此列表中的指定位置插入指定的元素。  *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123;    rangeCheckForAdd(index);    ensureCapacityInternal(size + 1);  // Increments modCount!!    //arraycopy()方法实现数组自己复制自己    //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量；    System.arraycopy(elementData, index, elementData, index + 1, size - index);    elementData[index] = element;    size++;&#125;又如toArray()方法中用到了copyOf()方法\n12345678910/** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。  *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */public Object[] toArray() &#123;//elementData：要复制的数组；size：要复制的长度    return Arrays.copyOf(elementData, size);&#125;两者联系与区别联系：看两者源代码可以发现copyOf()内部调用了System.arraycopy()方法区别：\narraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置copyOf()是系统自动在内部新建一个数组，并返回该数组。ArrayList 核心扩容技术　　扩容机制代码已经做了详细的解释。另外值得注意的是大家很容易忽略的一个运算符：移位运算符　　简介：移位运算符就是在二进制的基础上对数字进行平移。按照平移的方向和填充数字的规则分为三种:&lt;&lt;(左移)、&gt;&gt;(带符号右移)和&gt;&gt;&gt;(无符号右移)。　　作用：对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源　　比如这里：int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。另外需要注意的是：\njava 中的length 属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性.java 中的length()方法是针对字 符串String说的,如果想看这个字符串的长度则用到 length()这个方法..java 中的size()方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!内部类1234(1)private class Itr implements Iterator&lt;E&gt;  (2)private class ListItr extends Itr implements ListIterator&lt;E&gt;  (3)private class SubList extends AbstractList&lt;E&gt; implements RandomAccess  (4)static final class ArrayListSpliterator&lt;E&gt; implements Spliterator&lt;E&gt;　　ArrayList有四个内部类，其中的Itr是实现了Iterator接口，同时重写了里面的hasNext()， next()， remove() 等方法；其中的ListItr 继承 Itr，实现了ListIterator接口，同时重写了hasPrevious()， nextIndex()， previousIndex()， previous()， set(E e)， add(E e) 等方法，所以这也可以看出了 Iterator和ListIterator的区别: ListIterator在Iterator的基础上增加了添加对象，修改对象，逆向遍历等方法，这些是Iterator不能实现的。\nArrayList经典Demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package list;import java.util.ArrayList;import java.util.Iterator;public class ArrayListDemo &#123;    public static void main(String[] srgs)&#123;         ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();         System.out.printf(\"Before add:arrayList.size() = %d\\n\",arrayList.size());         arrayList.add(1);         arrayList.add(3);         arrayList.add(5);         arrayList.add(7);         arrayList.add(9);         System.out.printf(\"After add:arrayList.size() = %d\\n\",arrayList.size());         System.out.println(\"Printing elements of arrayList\");         // 三种遍历方式打印元素         // 第一种：通过迭代器遍历         System.out.print(\"通过迭代器遍历:\");         Iterator&lt;Integer&gt; it = arrayList.iterator();         while(it.hasNext())&#123;             System.out.print(it.next() + \" \");         &#125;         System.out.println();         // 第二种：通过索引值遍历         System.out.print(\"通过索引值遍历:\");         for(int i = 0; i &lt; arrayList.size(); i++)&#123;             System.out.print(arrayList.get(i) + \" \");         &#125;         System.out.println();         // 第三种：for循环遍历         System.out.print(\"for循环遍历:\");         for(Integer number : arrayList)&#123;             System.out.print(number + \" \");         &#125;         // toArray用法         // 第一种方式(最常用)         Integer[] integer = arrayList.toArray(new Integer[0]);         // 第二种方式(容易理解)         Integer[] integer1 = new Integer[arrayList.size()];         arrayList.toArray(integer1);         // 抛出异常，java不支持向下转型         //Integer[] integer2 = new Integer[arrayList.size()];         //integer2 = arrayList.toArray();         System.out.println();         // 在指定位置添加元素         arrayList.add(2,2);         // 删除指定位置上的元素         arrayList.remove(2);             // 删除指定元素         arrayList.remove((Object)3);         // 判断arrayList是否包含5         System.out.println(\"ArrayList contains 5 is: \" + arrayList.contains(5));         // 清空ArrayList         arrayList.clear();         // 判断ArrayList是否为空         System.out.println(\"ArrayList is empty: \" + arrayList.isEmpty());    &#125;&#125;","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/21/blankbusinesscompositioncomputer373076.jpg","plink":"https://snailscoder.com/2020/04/21/java/arraylist/"},{"title":"synchronized关键字和volatile关键字的区别","date":"2020-04-14T14:37:00.000Z","date_formatted":{"ll":"2020年4月14日","L":"2020/04/14","MM-DD":"04-14"},"updated":"2020-04-14T09:14:21.640Z","content":"并发编程的三个重要特性原子性: 一个操作或多个操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。synchronized可以保证代码片段的原子性。可见性: 当一个变量对共享变量做了修改，那么另外的线程都立即可以看到修改后的最新值。volatile关键字可以保证共享变量的可见性。有序性: 代码在执行的过程中的先后顺序，Java在编译器以及运行期间的优化，代码的执行顺序未必就是按编写代码的顺序。volatile关键字可以禁止指令进行重排序优化。synchronized关键字和volatile关键字的区别volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量，而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后效率有了显著的提升，实际开发中使用synchronized关键字的场景还是更多一些。多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能发生阻塞。volatile关键字能保证数据的可见性，但不能保障原子性。synchronized关键字两者都能保障。volatile关键字主要用于解决变量在多个线程之间的可见性，而synchronized关键字解决的是多个线程之间访问资源的同步性。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/14/102.png","plink":"https://snailscoder.com/2020/04/14/java/sync-volatile/"},{"title":"【转】synchronized关键字最主要的三种使用方式的总结","date":"2020-04-14T14:16:00.000Z","date_formatted":{"ll":"2020年4月14日","L":"2020/04/14","MM-DD":"04-14"},"updated":"2020-04-14T06:26:07.634Z","content":"\nsynchronized关键字最主要的三种使用方式的总结修饰实例方法，作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 。也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份，所以对该类的所有对象都加了锁）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码块前要获得给定对象的锁。 和 synchronized 方法一样，synchronized(this)代码块也是锁定当前对象的。synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。这里再提一下：synchronized关键字加到非 static 静态方法上是给对象实例上锁。另外需要注意的是：尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓冲功能！下面我已一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。\n面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！”\n双重校验锁实现对象单例（线程安全）\n1234567891011121314151617181920public class Singleton &#123;    private volatile static Singleton uniqueInstance;    private Singleton() &#123;    &#125;    public static Singleton getUniqueInstance() &#123;       //先判断对象是否已经实例过，没有实例化过才进入加锁代码        if (uniqueInstance == null) &#123;            //类对象加锁            synchronized (Singleton.class) &#123;                if (uniqueInstance == null) &#123;                    uniqueInstance = new Singleton();                &#125;            &#125;        &#125;        return uniqueInstance;    &#125;&#125;另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。\nuniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：\n为 uniqueInstance 分配内存空间初始化 uniqueInstance将 uniqueInstance 指向分配的内存地址但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。\n使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。\n###synchronized 关键字底层原理总结\nsynchronized 关键字底层原理属于 JVM 层面。\n① synchronized 同步语句块的情况\n1234567public class SynchronizedDemo &#123;\tpublic void method() &#123;\t\tsynchronized (this) &#123;\t\t\tSystem.out.println(\"synchronized 代码块\");\t\t&#125;\t&#125;&#125;通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 javac SynchronizedDemo.java 命令生成编译后的 .class 文件，然后执行javap -c -s -v -l SynchronizedDemo.class。\n\n从上面我们可以看出：\nsynchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\n② synchronized 修饰方法的的情况\n12345public class SynchronizedDemo2 &#123;\tpublic synchronized void method() &#123;\t\tSystem.out.println(\"synchronized 方法\");\t&#125;&#125;\nsynchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\n在 Java 早期版本中，synchronized 属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。\nJDK1.6 之后的底层优化JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。\n锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。\n①偏向锁\n引入偏向锁的目的和引入轻量级锁的目的很像，他们都是为了没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。但是不同是：轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉。\n偏向锁的“偏”就是偏心的偏，它的意思是会偏向于第一个获得它的线程，如果在接下来的执行中，该锁没有被其他线程获取，那么持有偏向锁的线程就不需要进行同步！关于偏向锁的原理可以查看《深入理解Java虚拟机：JVM高级特性与最佳实践》第二版的13章第三节锁优化。\n但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。\n② 轻量级锁\n倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)。轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。 关于轻量级锁的加锁和解锁的原理可以查看《深入理解Java虚拟机：JVM高级特性与最佳实践》第二版的13章第三节锁优化。\n轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！\n③  自旋锁和自适应自旋\n轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。\n互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。\n一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。 所以，虚拟机的开发团队就这样去考虑：“我们能不能让后面来的请求获取锁的线程等待一会而不被挂起呢？看看持有锁的线程是否很快就会释放锁”。为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋），这项技术就叫做自旋。\n百度百科对自旋锁的解释：\n\n何谓自旋锁？它是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。\n\n自旋锁在 JDK1.6 之前其实就已经引入了，不过是默认关闭的，需要通过--XX:+UseSpinning参数来开启。JDK1.6及1.6之后，就改为默认开启的了。需要注意的是：自旋等待不能完全替代阻塞，因为它还是要占用处理器时间。如果锁被占用的时间短，那么效果当然就很好了！反之，相反！自旋等待的时间必须要有限度。如果自旋超过了限定次数任然没有获得锁，就应该挂起线程。自旋次数的默认值是10次，用户可以修改--XX:PreBlockSpin来更改。\n另外,在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。\n④ 锁消除\n锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。\n⑤ 锁粗化\n原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，——直在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。\n大部分情况下，上面的原则都是没有问题的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，那么会带来很多不必要的性能消耗。\nSynchronized 和 ReenTrantLock 的对比① 两者都是可重入锁\n两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。\n② synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API\nsynchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。\n③ ReenTrantLock 比 synchronized 增加了一些高级功能\n相比synchronized，ReenTrantLock增加了一些高级功能。主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）\nReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。如果你想使用上述功能，那么选择ReenTrantLock是一个不错的选择。\n④ 性能已不是选择标准\n在JDK1.6之前，synchronized 的性能是比 ReenTrantLock 差很多。具体表示为：synchronized 关键字吞吐量随线程数的增加，下降得非常严重。而ReenTrantLock 基本保持一个比较稳定的水平。我觉得这也侧面反映了， synchronized 关键字还有非常大的优化余地。后续的技术发展也证明了这一点，我们上面也讲了在 JDK1.6 之后 JVM 团队对 synchronized 关键字做了很多优化。JDK1.6 之后，synchronized 和 ReenTrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReenTrantLock 的文章都是错的！JDK1.6之后，性能已经不是选择synchronized和ReenTrantLock的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的synchronized，所以还是提倡在synchronized能满足你的需求的情况下，优先考虑使用synchronized关键字来进行同步！优化后的synchronized和ReenTrantLock一样，在很多地方都是用到了CAS操作。\n以上内容转自:https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md\n","plink":"https://snailscoder.com/2020/04/14/java/synchronized/"},{"title":"双重校验锁实现对象单例（线程安全）","date":"2020-04-14T12:16:00.000Z","date_formatted":{"ll":"2020年4月14日","L":"2020/04/14","MM-DD":"04-14"},"updated":"2020-04-14T09:30:30.575Z","content":"1234567891011121314151617public class Singleton&#123;    private volatile static Singleton uniqueInstance;        private Singleton()&#123;&#125;        public static Singleton getUniqueInstance()&#123;        &#x2F;&#x2F;先判断对象是否已经实例化过才进行加锁代码        if(uniqueInstance &#x3D;&#x3D; null)&#123;            synchronized(Singleton.class)&#123;                if(uniqueInstance &#x3D;&#x3D; null)&#123;                    uniqueInstance &#x3D; new Singleton();                &#125;            &#125;        &#125;        return uniqueInstance;    &#125;&#125;使用volatile可以禁止JVM的指令重排，保证多线程环境下也能正常运行。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/14/257897.jpg","plink":"https://snailscoder.com/2020/04/14/java/Singleton/"},{"title":"【转】Java 8系列之重新认识HashMap","date":"2020-04-14T12:16:00.000Z","date_formatted":{"ll":"2020年4月14日","L":"2020/04/14","MM-DD":"04-14"},"updated":"2020-04-14T04:20:39.255Z","content":"内容详见：Java 8系列之重新认识HashMap\n","plink":"https://snailscoder.com/2020/04/14/java/hashmap-01/"},{"title":"【转】通过源码一步步分析ArrayList扩容机制","date":"2020-04-14T11:55:25.000Z","date_formatted":{"ll":"2020年4月14日","L":"2020/04/14","MM-DD":"04-14"},"updated":"2020-04-14T04:16:31.319Z","content":"一 先从 ArrayList 的构造函数说起ArrayList有三种方式来初始化，构造方法源码如下：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/**  * 默认初始容量大小  */ private static final int DEFAULT_CAPACITY = 10;  private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /**  *默认构造函数，使用初始容量10构造一个空列表(无参数构造)  */ public ArrayList() &#123;     this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125;  /**  * 带初始容量参数的构造函数。（用户自己指定容量）  */ public ArrayList(int initialCapacity) &#123;     if (initialCapacity &gt; 0) &#123;//初始容量大于0         //创建initialCapacity大小的数组         this.elementData = new Object[initialCapacity];     &#125; else if (initialCapacity == 0) &#123;//初始容量等于0         //创建空数组         this.elementData = EMPTY_ELEMENTDATA;     &#125; else &#123;//初始容量小于0，抛出异常         throw new IllegalArgumentException(\"Illegal Capacity: \"+                                            initialCapacity);     &#125; &#125;/** *构造包含指定collection元素的列表，这些元素利用该集合的迭代器按顺序返回 *如果指定的集合为null，throws NullPointerException。  */  public ArrayList(Collection&lt;? extends E&gt; c) &#123;     elementData = c.toArray();     if ((size = elementData.length) != 0) &#123;         // c.toArray might (incorrectly) not return Object[] (see 6260652)         if (elementData.getClass() != Object[].class)             elementData = Arrays.copyOf(elementData, size, Object[].class);     &#125; else &#123;         // replace with empty array.         this.elementData = EMPTY_ELEMENTDATA;     &#125; &#125;细心的同学一定会发现 ：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10。 下面在我们分析 ArrayList 扩容时会讲到这一点内容！\n二 一步一步分析 ArrayList 扩容机制这里以无参构造函数创建的 ArrayList 为例分析\n1. 先来看 add 方法12345678910 /**  * 将指定的元素追加到此列表的末尾。   */ public boolean add(E e) &#123;//添加元素之前，先调用ensureCapacityInternal方法     ensureCapacityInternal(size + 1);  // Increments modCount!!     //这里看到ArrayList添加元素的实质就相当于为数组赋值     elementData[size++] = e;     return true; &#125;2. 再来看看 ensureCapacityInternal() 方法可以看到 add 方法 首先调用了ensureCapacityInternal(size + 1)\n123456789//得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123;     if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;           // 获取默认的容量和传入参数的较大值         minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);     &#125;     ensureExplicitCapacity(minCapacity); &#125;当 要 add 进第1个元素时，minCapacity为1，在Math.max()方法比较后，minCapacity 为10。\n3. ensureExplicitCapacity() 方法如果调用 ensureCapacityInternal() 方法就一定会进过（执行）这个方法，下面我们来研究一下这个方法的源码！\n123456789//判断是否需要扩容  private void ensureExplicitCapacity(int minCapacity) &#123;      modCount++;      // overflow-conscious code      if (minCapacity - elementData.length &gt; 0)          //调用grow方法进行扩容，调用此方法代表已经开始扩容了          grow(minCapacity);  &#125;我们来仔细分析一下：\n当我们要 add 进第1个元素到 ArrayList 时，elementData.length 为0 （因为还是一个空的 list），因为执行了 ensureCapacityInternal() 方法 ，所以 minCapacity 此时为10。此时，minCapacity - elementData.length &gt; 0成立，所以会进入 grow(minCapacity) 方法。当add第2个元素时，minCapacity 为2，此时e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length &gt; 0 不成立，所以不会进入 （执行）grow(minCapacity) 方法。添加第3、4···到第10个元素时，依然不会执行grow方法，数组容量都为10。直到添加第11个元素，minCapacity(为11)比elementData.length（为10）要大。进入grow方法进行扩容。\n4. grow() 方法123456789101112131415161718192021222324/** * 要分配的最大数组大小 */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * ArrayList扩容的核心方法。 */private void grow(int minCapacity) &#123;    // oldCapacity为旧容量，newCapacity为新容量    int oldCapacity = elementData.length;    //将oldCapacity 右移一位，其效果相当于oldCapacity /2，    //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);    //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;   // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，   //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    // minCapacity is usually close to size, so this is a win:    elementData = Arrays.copyOf(elementData, newCapacity);&#125;int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity为偶数就是1.5倍，否则是1.5倍左右）！  奇偶不同，比如 ：10+10/2 = 15, 33+33/2=49。如果是奇数的话会丢掉小数.\n\n  “&gt;&gt;”（移位运算符）：&gt;&gt;1 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 　\n\n我们再来通过例子探究一下grow() 方法 ：\n当add第1个元素时，oldCapacity 为0，经比较后第一个if判断成立，newCapacity = minCapacity(为10)。但是第二个if判断不会成立，即newCapacity 不比 MAX_ARRAY_SIZE大，则不会进入 hugeCapacity 方法。数组容量为10，add方法中 return true,size增为1。当add第11个元素进入grow方法时，newCapacity为15，比minCapacity（为11）大，第一个if判断不成立。新容量没有大于数组最大size，不会进入hugeCapacity方法。数组容量扩为15，add方法中return true,size增为11。以此类推······这里补充一点比较重要，但是容易被忽视掉的知识点：\njava 中的 length属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性.java 中的 length() 方法是针对字符串说的,如果想看这个字符串的长度则用到 length() 这个方法.java 中的 size() 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!5. hugeCapacity() 方法。从上面 grow() 方法源码我们知道： 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) hugeCapacity() 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，如果minCapacity大于最大容量，则新容量则为Integer.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 Integer.MAX_VALUE - 8。 \n1234567891011private static int hugeCapacity(int minCapacity) &#123;    if (minCapacity &lt; 0) // overflow        throw new OutOfMemoryError();    //对minCapacity和MAX_ARRAY_SIZE进行比较    //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小    //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小    //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;    return (minCapacity &gt; MAX_ARRAY_SIZE) ?        Integer.MAX_VALUE :        MAX_ARRAY_SIZE;&#125;三 System.arraycopy() 和 Arrays.copyOf()方法阅读源码的话，我们就会发现 ArrayList 中大量调用了这两个方法。比如：我们上面讲的扩容操作以及add(int index, E element)、toArray() 等方法中都用到了该方法！\n3.1 System.arraycopy() 方法123456789101112131415/** * 在此列表中的指定位置插入指定的元素。  *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123;    rangeCheckForAdd(index);    ensureCapacityInternal(size + 1);  // Increments modCount!!    //arraycopy()方法实现数组自己复制自己    //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量；    System.arraycopy(elementData, index, elementData, index + 1, size - index);    elementData[index] = element;    size++;&#125;我们写一个简单的方法测试以下：\n1234567891011121314151617public class ArraycopyTest &#123;\tpublic static void main(String[] args) &#123;\t\t// TODO Auto-generated method stub\t\tint[] a = new int[10];\t\ta[0] = 0;\t\ta[1] = 1;\t\ta[2] = 2;\t\ta[3] = 3;\t\tSystem.arraycopy(a, 2, a, 3, 3);\t\ta[2]=99;\t\tfor (int i = 0; i &lt; a.length; i++) &#123;\t\t\tSystem.out.println(a[i]);\t\t&#125;\t&#125;&#125;结果：\n10 1 99 2 3 0 0 0 0 03.2 Arrays.copyOf()方法1234567/**  以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; 返回的数组的运行时类型是指定数组的运行时类型。   */ public Object[] toArray() &#123; //elementData：要复制的数组；size：要复制的长度     return Arrays.copyOf(elementData, size); &#125;个人觉得使用 Arrays.copyOf()方法主要是为了给原有数组扩容，测试代码如下：\n1234567891011public class ArrayscopyOfTest &#123;\tpublic static void main(String[] args) &#123;\t\tint[] a = new int[3];\t\ta[0] = 0;\t\ta[1] = 1;\t\ta[2] = 2;\t\tint[] b = Arrays.copyOf(a, 10);\t\tSystem.out.println(\"b.length\"+b.length);\t&#125;&#125;结果：\n1103.3 两者联系和区别联系： \n看两者源代码可以发现 copyOf() 内部实际调用了 System.arraycopy() 方法 \n区别：\narraycopy() 需要目标数组，将原数组拷贝到你自己定义的数组里或者原数组，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf() 是系统自动在内部新建一个数组，并返回该数组。\n四 ensureCapacity方法ArrayList 源码中有一个 ensureCapacity 方法不知道大家注意到没有，这个方法 ArrayList 内部没有被调用过，所以很显然是提供给用户调用的，那么这个方法有什么作用呢？\n1234567891011121314151617/**如有必要，增加此 ArrayList 实例的容量，以确保它至少可以容纳由minimum capacity参数指定的元素数。 * * @param   minCapacity   所需的最小容量 */public void ensureCapacity(int minCapacity) &#123;    int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)        // any size if not default element table        ? 0        // larger than default for default empty table. It's already        // supposed to be at default size.        : DEFAULT_CAPACITY;    if (minCapacity &gt; minExpand) &#123;        ensureExplicitCapacity(minCapacity);    &#125;&#125;最好在 add 大量元素之前用 ensureCapacity 方法，以减少增量重新分配的次数\n我们通过下面的代码实际测试以下这个方法的效果：\n12345678910111213public class EnsureCapacityTest &#123;\tpublic static void main(String[] args) &#123;\t\tArrayList&lt;Object&gt; list = new ArrayList&lt;Object&gt;();\t\tfinal int N = 10000000;\t\tlong startTime = System.currentTimeMillis();\t\tfor (int i = 0; i &lt; N; i++) &#123;\t\t\tlist.add(i);\t\t&#125;\t\tlong endTime = System.currentTimeMillis();\t\tSystem.out.println(\"使用ensureCapacity方法前：\"+(endTime - startTime));\t&#125;&#125;运行结果：\n1使用ensureCapacity方法前：21581234567891011121314public class EnsureCapacityTest &#123;    public static void main(String[] args) &#123;        ArrayList&lt;Object&gt; list = new ArrayList&lt;Object&gt;();        final int N = 10000000;        list = new ArrayList&lt;Object&gt;();        long startTime1 = System.currentTimeMillis();        list.ensureCapacity(N);        for (int i = 0; i &lt; N; i++) &#123;            list.add(i);        &#125;        long endTime1 = System.currentTimeMillis();        System.out.println(\"使用ensureCapacity方法后：\"+(endTime1 - startTime1));    &#125;&#125;运行结果：\n12使用ensureCapacity方法前：1773通过运行结果，我们可以看出向 ArrayList 添加大量元素之前最好先使用ensureCapacity 方法，以减少增量重新分配的次数。\n转自:通过源码一步步分析ArrayList扩容机制\n","plink":"https://snailscoder.com/2020/04/14/java/arraylist-grow/"},{"title":"高并发系统：消息队列使用","date":"2020-04-13T17:30:00.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T15:18:07.410Z","content":"在历年的工作经历中，一直把消息队列看作暂时存储数据的一个容器，认为它是一个平衡低速系统和高速系统处理任务时间差的工具。我理解的消息队列在高并发系统设计中起到的作用的主要有以下三点：\n削峰填谷:可以削去到达秒杀系统的峰值流量，让业务逻辑的处理更加缓和，但会造成请求处理的延迟；异步处理:可以简化业务流程中的步骤，提升系统性能，但是你需要分清同步流程和异步流程的边界；解耦合:可以将秒杀系统和数据系统解耦开，这样两个系统的任何变更都不会影响到另一个系统。以秒杀场景为例：\n削峰填谷在秒杀场景下短时间之内数据库的写流量会很高，但高并发的写请求并不是持续的，也不是经常发生的，而只有在秒杀活动开始后的几秒或者十几秒时间内才会存在。在数据库层面下功夫来提高性能有点得不偿失。\n所以我们的思路是：将秒杀请求暂存在消息队列中，然后业务服务器会响应用户“秒杀结果正在计算中”，释放了系统资源之后再处理其它用户的请求。\n我们会在后台启动若干个队列处理程序消费消息队列中的消息，再执行校验库存、下单等逻辑。因为只有有限个队列处理线程在执行，所以落入后端数据库上的并发请求是有限的。而请求是可以在消息队列中被短暂地堆积，当库存被消耗完之后，消息队列中堆积的请求就可以被丢弃了。\n这就是消息队列在秒杀系统中最主要的作用：削峰填谷，也就是说它可以削平短暂的流量高峰，虽说堆积会造成请求被短暂延迟处理，但是只要我们时刻监控消息队列中的堆积长度，在堆积量超过一定量时，增加队列处理机数量来提升消息的处理能力就好了，而且秒杀的用户对于短暂延迟知晓秒杀的结果也是有一定容忍度的。\n这里需要注意一下，我所说的是“短暂”延迟，如果长时间没有给用户公示秒杀结果，那么用户可能就会怀疑你的秒杀活动有猫腻了。所以在使用消息队列应对流量峰值时，需要对队列处理的时间、前端写入流量的大小、数据库处理能力做好评估，然后根据不同的量级来决定部署多少台队列处理程序。\n异步处理其实在大量的写请求“攻击”你的电商系统的时候，消息队列除了发挥主要的削峰填谷的作用之外，还可以实现异步处理来简化秒杀请求中的业务流程，提升系统的性能。\n\n你想，在刚才提到的秒杀场景下，我们在处理购买请求时需要 500ms。这时你分析了一下整个的购买流程，发现这里面会有主要的业务逻辑，也会有次要的业务逻辑：比如说，主要的流程是生成订单、扣减库存；次要的流程可能是我们在下单购买成功之后会给用户发放优惠券，会增加用户的积分。\n解耦合除了异步处理和削峰填谷以外，消息队列在秒杀系统中起到的另一个作用是解耦合。\n比如数据团队对你说，在秒杀活动之后想要统计活动的数据，借此来分析活动商品的受欢迎程度、购买者人群的特点以及用户对于秒杀互动的满意程度等等指标。而我们需要将大量的数据发送给数据团队，那么要怎么做呢？\n一个思路是：使用 HTTP 或者 RPC 的方式来同步地调用，也就是数据团队这边提供一个接口，我们实时将秒杀的数据推送给它，但是这样调用会有两个问题：\n整体系统的耦合性比较强，当数据团队的接口发生故障时，会影响到秒杀系统的可用性。当数据系统需要新的字段，就要变更接口的参数，那么秒杀系统也要随着一起变更。这时，我们可以考虑使用消息队列降低业务系统和数据系统的直接耦合度。\n秒杀系统产生一条购买数据后，我们可以先把全部数据发送给消息队列，然后数据团队再订阅这个消息队列的话题，这样它们就可以接收到数据，然后再做过滤和处理了。\n秒杀系统在这样解耦合之后，数据系统的故障就不会影响到秒杀系统了，同时当数据系统需要新的字段时，只需要解析消息队列中的消息，拿到需要的数据就好了。\n\n总结消息队列在高并发系统设计中起到的作用以及一些注意事项，重点如下：\n削峰填谷是消息队列最主要的作用，但是会造成请求处理的延迟。异步处理是提升系统性能的神器，但是你需要分清同步流程和异步流程的边界，同时消息存在着丢失的风险，我们需要考虑如何确保消息一定到达。解耦合可以提升你的整体系统的鲁棒性。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/queue01.png","plink":"https://snailscoder.com/2020/04/13/architect/queue-01/"},{"title":"高并发系统：缓存使用-缓存穿透","date":"2020-04-13T14:30:20.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T06:33:19.935Z","content":"在低缓存命中率的系统中，大量查询信息的请求会穿透缓存到数据库，因为数据库对于并发的承受能力是比较脆弱的。一旦数据库承受不了，查询就会变慢，大量的请求也会阻塞在数据库查询上，造成应用服务器的连接和线程资源被占满，最终导致你的电商系统崩溃。\n一般来说，我们的核心缓存的命中率要保持在 99% 以上，非核心缓存的命中率也要尽量保证在 90%，如果低于这个标准你可能就需要优化缓存的使用方式了。\n什么是缓存穿透缓存穿透其实是指从缓存中没有查到数据，而不得不从后端系统（比如数据库）中查询的情况。\n互联网系统的数据访问模型一般会遵从“80/20 原则”。大部分流量都在 20% 的热点数据上，而另外的 80% 的数据则不会被经常访问。理论上说，我们只需要在有限的缓存空间里存储 20% 的热点数据就可以有效地保护脆弱的后端系统了，也就可以放弃缓存另外 80% 的非热点数据了。所以这种少量的缓存穿透是不可避免的，但是对系统是没有损害的。\n缓存穿透的解决方案那如何解决缓存穿透呢？一般来说我们会有两种解决方案：回种空值以及使用布隆过滤器。\n1、回种空值当我们从数据库中查询到空值或者发生异常时，我们可以向缓存中回种一个空值。但是因为空值并不是准确的业务数据，并且会占用缓存的空间，所以我们会给这个空值加一个比较短的过期时间，让空值在短时间之内能够快速过期淘汰。下面是这个流程的伪代码：\n1234567891011Object nullValue &#x3D; new Object();try &#123;  Object valueFromDB &#x3D; getFromDB(uid); &#x2F;&#x2F;从数据库中查询数据  if (valueFromDB &#x3D;&#x3D; null) &#123;    cache.set(uid, nullValue, 10);   &#x2F;&#x2F;如果从数据库中查询到空值，就把空值写入缓存，设置较短的超时时间  &#125; else &#123;    cache.set(uid, valueFromDB, 1000);  &#125;&#125; catch(Exception e) &#123;  cache.set(uid, nullValue, 10);&#125;回种空值缺点：虽然能够阻挡大量穿透的请求，但如果有大量不存在信息的查询请求，缓存内就会有有大量的空值缓存，也就会浪费缓存的存储空间，如果缓存空间被占满了，还会剔除掉一些已经被缓存的有效信息反而会造成缓存命中率的下降。所以这个方案，我建议你在使用的时候应该评估一下缓存容量是否能够支撑。\n2、使用布隆过滤器布隆过滤器说明1970 年布隆提出了一种布隆过滤器的算法，用来判断一个元素是否在一个集合中。这种算法由一个二进制数组和一个 Hash 算法组成。它的基本思路如下：我们把集合中的每一个值按照提供的 Hash 算法算出对应的 Hash 值，然后将 Hash 值对数组长度取模后得到需要计入数组的索引值，并且将数组这个位置的值从 0 改成 1。在判断一个元素是否存在于这个集合中时，你只需要将这个元素按照相同的算法计算出索引值，如果这个位置的值为 1 就认为这个元素在集合中，否则则认为不在集合中。下图是布隆过滤器示意图，我来带你分析一下图内的信息。\nA、B、C 等元素组成了一个集合，元素 D 计算出的 Hash 值所对应的的数组中值是 1，所以可以认为 D 也在集合中。而 F 在数组中的值是 0，所以 F 不在数组中。\n使用布隆过滤器来解决缓存穿透的问题还是以存储用户信息的表为例进行讲解。首先我们初始化一个很大的数组，比方说长度为 20 亿的数组，接下来我们选择一个 Hash 算法，然后我们将目前现有的所有用户的 ID 计算出 Hash 值并且映射到这个大数组中，映射位置的值设置为 1，其它值设置为 0。新注册的用户除了需要写入到数据库中之外，它也需要依照同样的算法更新布隆过滤器的数组中相应位置的值。那么当我们需要查询某一个用户的信息时，先查询这个 ID 在布隆过滤器中是否存在，如果不存在就直接返回空值，而不需要继续查询数据库和缓存，这样就可以极大地减少异常查询带来的缓存穿透。\n布隆过滤器拥有极高的性能，无论是写入操作还是读取操作，时间复杂度都是 O(1) 是常量值。在空间上，相对于其他数据结构它也有很大的优势，比如，20 亿的数组需要 2000000000/8/1024/1024 = 238M 的空间，而如果使用数组来存储，假设每个用户 ID 占用 4 个字节的空间，那么存储 20 亿用户需要 2000000000 * 4 / 1024 / 1024 = 7600M 的空间，是布隆过滤器的 32 倍。\n布隆过滤器缺陷1. 它在判断元素是否在集合中时是有一定错误几率的，比如它会把不是集合中的元素判断为处在集合中:    主要是 Hash 算法的问题，Hash 算法存在着一定的碰撞几率。但因为布隆过滤器的特点恰巧非常适合解决缓存穿透的问题。因为当布隆过滤器判断元素在集合中时，这个元素可能不在集合中。但是一旦布隆过滤器判断这个元素不在集合中时，它一定不在集合中。    当然如果在乎碰撞率问题，解决方案是：使用多个 Hash 算法为元素计算出多个 Hash 值，只有所有 Hash 值对应的数组中的值都为 1 时，才会认为这个元素在集合中。\n2. 不支持删除元素。布隆过滤器不支持删除元素的缺陷也和 Hash 碰撞有关。假如两个元素 A 和 B 都是集合中的元素，它们有相同的 Hash 值，它们就会映射到数组的同一个位置。这时我们删除了 A，数组中对应位置的值也从 1 变成 0，那么在判断 B 的时候发现值是 0，也会判断 B 是不在集合中的元素，就会得到错误的结论。解决方案是：将标志位0，1修改为计数方式。缺点是增加空间消耗。\n所以，你要依据业务场景来选择是否能够使用布隆过滤器\n总的来说，回种空值和布隆过滤器是解决缓存穿透问题的两种最主要的解决方案，但是它们也有各自的适用场景，并不能解决所有问题。\ndog-pile effect（狗桩效应）当有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力，我们把这个场景叫做“dog-pile effect”（狗桩效应），解决方案：\n在代码中控制在某一个热点缓存项失效之后启动一个后台线程，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都不再穿透而直接返回。通过在 Memcached 或者 Redis 中设置分布式锁，只有获取到锁的请求才能够穿透到数据库。综上回种空值是一种最常见的解决思路，实现起来也最简单，如果评估空值缓存占据的缓存空间可以接受，那么可以优先使用这种方案；布隆过滤器会引入一个新的组件，也会引入一些开发上的复杂度和运维上的成本。所以只有在存在海量查询数据库中，不存在数据的请求时才会使用，在使用时也要关注布隆过滤器对内存空间的消耗；对于极热点缓存数据穿透造成的“狗桩效应”，可以通过设置分布式锁或者后台线程定时加载的方式来解决。参考:布隆过滤器\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/caffeine.jpg","plink":"https://snailscoder.com/2020/04/13/architect/cache-03/"},{"title":"高并发系统：缓存使用-CDN静态缓存","date":"2020-04-13T14:30:20.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T07:12:51.826Z","content":"日常项目中存在哪些静态资源：\n对于移动 APP 来说，这些静态资源主要是图片、视频和流媒体信息；对于 Web 网站来说，则包括了 JavaScript 文件、CSS 文件、静态 HTML 文件等等。读请求量极大并且对访问速度的要求很高还占据了很高的带宽，这时会出现访问速度慢带宽被占满影响动态请求的问题，那么你就需要考虑如何针对这些静态资源进行读加速了。\nCDN 的关键技术CDN（Content Delivery Network/Content Distribution Network，内容分发网络）。简单来说，CDN 就是将静态的资源分发到位于多个地理位置机房中的服务器上，因此它能很好地解决数据就近访问的问题，也就加快了静态资源的访问速度。\n在大中型公司里面，CDN 的应用非常普遍，大公司为了提供更稳定的 CDN 服务会选择自建 CDN，而大部分公司基于成本的考虑还是会选择专业的 CDN 厂商，网宿、阿里云、腾讯云、蓝汛等等，其中网宿和蓝汛是老牌的 CDN 厂商，阿里云和腾讯云是云厂商提供的服务，如果你的服务部署在云上可以选择相应云厂商的 CDN 服务，这些 CDN 厂商都是现今行业内比较主流的。\n\n待补充。。。\n","plink":"https://snailscoder.com/2020/04/13/architect/cache-04/"},{"title":"高并发系统：缓存使用-读写策略","date":"2020-04-13T11:30:25.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T03:37:00.310Z","content":"我们在选择缓存读写策略时需要考虑诸多的因素，比如说，缓存中是否有可能被写入脏数据，策略的读写性能如何，是否存在缓存命中率下降的情况等等。我就以标准的“缓存 + 数据库”的场景为例，剖析经典的缓存读写策略以及它们适用的场景。这样一来，你就可以在日常的工作中根据不同的场景选择不同的读写策略。\n一、Cache Aside（旁路缓存）策略这个策略就是我们使用缓存最常见的策略，Cache Aside 策略（也叫旁路缓存策略），这个策略数据以数据库中的数据为准，缓存中的数据是按需加载的。\n它可以分为读策略和写策略其中读策略的步骤是：\n从缓存中读取数据；如果缓存命中，则直接返回数据；如果缓存不命中，则从数据库中查询数据；查询到数据后，将数据写入到缓存中，并且返回给用户。写策略的步骤是：\n更新数据库中的记录；删除缓存记录。\nCache Aside 策略是我们日常开发中最经常使用的缓存策略，不过我们在使用时也要学会依情况而变。比如说当新注册一个用户，按照这个更新策略，你要写数据库，然后清理缓存（当然缓存中没有数据给你清理）。可当我注册用户后立即读取用户信息，并且数据库主从分离时，会出现因为主从延迟所以读不到用户信息的情况。而解决这个问题的办法恰恰是在插入新数据到数据库之后写入缓存，这样后续的读请求就会从缓存中读到数据了。并且因为是新注册的用户，所以不会出现并发更新用户信息的情况。\nCache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：\n一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。\n二、Read/Write Through（读穿 / 写穿）策略这个策略的核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据。\n1、Write Through 策略先查询要写入的数据在缓存中是否已经存在\n如果已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中如果缓存中数据不存在，我们把这种情况叫做“Write Miss（写失效）”我们可以选择两种“Write Miss”方式：\n\nWrite Allocate（按写分配）:做法是写入缓存相应位置，再由缓存组件同步更新到数据库中；No-write allocate（不按写分配）:做法是不写入缓存中，而是直接更新到数据库中。\n\n在 Write Through 策略中，我们一般选择“No-write allocate”方式，原因是无论采用哪种“Write Miss”方式，我们都需要同步将数据更新到数据库中，而“No-write allocate”方式相比“Write Allocate”还减少了一次缓存的写入，能够提升写入的性能。\n2、Read Through 策略先查询缓存中数据是否存在\n如果存在则直接返回如果不存在，则由缓存组件负责从数据库中同步加载数据。\nRead Through/Write Through 策略的特点是由缓存节点而非用户来和数据库打交道，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库，或者自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略，比如说在上一节中提到的本地缓存 Guava Cache 中的 Loading Cache 就有 Read Through 策略的影子。\n\n三、Write Back（写回）策略这个策略的核心思想是在写入数据时只写入缓存，并且把缓存块儿标记为“脏”的。而脏块儿只有被再次使用时才会将其中的数据写入到后端存储中。\n这种策略不能被应用到我们常用的数据库和缓存的场景中，它是计算机体系结构中的设计，比如我们在向磁盘中写数据时采用的就是这种策略。无论是操作系统层面的 Page Cache，还是日志的异步刷盘，亦或是消息队列中消息的异步写入磁盘，大多采用了这种策略。因为这个策略在性能上的优势毋庸置疑，它避免了直接写磁盘造成的随机写问题，毕竟写内存和写磁盘的随机 I/O 的延迟相差了几个数量级呢。\n\n\n当然，你依然可以在一些场景下使用这个策略，在使用时，我想给你的落地建议是：你在向低速设备写入数据的时候，可以在内存里先暂存一段时间的数据，甚至做一些统计汇总，然后定时地刷新到低速设备上。比如说，你在统计你的接口响应时间的时候，需要将每次请求的响应时间打印到日志中，然后监控系统收集日志后再做统计。但是如果每次请求都打印日志无疑会增加磁盘 I/O，那么不如把一段时间的响应时间暂存起来，经过简单的统计平均耗时，每个耗时区间的请求数量等等，然后定时地，批量地打印到日志中。\n\n总结1.Cache Aside 是我们在使用分布式缓存时最常用的策略，你可以在实际工作中直接拿来使用。2.Read/Write Through 和 Write Back 策略需要缓存组件的支持，所以比较适合你在实现本地缓存组件的时候使用；3.Write Back 策略是计算机体系结构中的策略，不过写入策略中的只写缓存，异步写入后端存储的策略倒是有很多的应用场景。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/kafei.jpg","plink":"https://snailscoder.com/2020/04/13/architect/cache-02/"},{"title":"高并发系统：缓存简介","date":"2020-04-13T10:30:20.000Z","date_formatted":{"ll":"2020年4月13日","L":"2020/04/13","MM-DD":"04-13"},"updated":"2020-04-13T09:22:33.501Z","content":"什么是缓存缓存，是一种存储数据的组件，它的作用是让对数据的请求更快地返回。凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存。\n常见硬件组件的延时情况从这些数据中，你可以看到，做一次内存寻址大概需要 100ns，而做一次磁盘的查找则需要 10ms。如果我们将做一次内存寻址的时间类比为一个课间，那么做一次磁盘查找相当于度过了大学的一个学期。可见，我们使用内存作为缓存的存储介质相比于以磁盘作为主要存储介质的数据库来说，性能上会提高多个数量级，同时也能够支撑更高的并发量。所以，内存是最常见的一种缓存数据的介质。\n缓存分类在我们日常开发中，常见的缓存主要就是分布式缓存、热点本地缓存、静态缓存这几种。\n分布式缓存分布式缓存的大名可谓是如雷贯耳了，我们平时耳熟能详的 Memcached、Redis 就是分布式缓存的典型例子。它们性能强劲，通过一些分布式的方案组成集群可以突破单机的限制。所以在整体架构中，分布式缓存承担着非常重要的角色，后边细谈。\n热点本地缓存当我们遇到极端的热点数据查询的时候。热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中，优势是不需要跨网络调度，速度极快，所以可以用来阻挡短时间内的热点查询。Guava 的 Loading Cache代码样例：\n123456789CacheBuilder&lt;String, List&lt;Product&gt;&gt; cacheBuilder &#x3D; CacheBuilder.newBuilder().maximumSize(maxSize).recordStats(); &#x2F;&#x2F;设置缓存最大值cacheBuilder &#x3D; cacheBuilder.refreshAfterWrite(30, TimeUnit.Seconds); &#x2F;&#x2F;设置刷新间隔LoadingCache&lt;String, List&lt;Product&gt;&gt; cache &#x3D; cacheBuilder.build(new CacheLoader&lt;String, List&lt;Product&gt;&gt;() &#123;    @Override    public List&lt;Product&gt; load(String k) throws Exception &#123;        return productService.loadAll(); &#x2F;&#x2F; 获取所有商品    &#125;&#125;);由于本地缓存是部署在应用服务器中，而我们应用服务器通常会部署多台，当数据更新时，我们不能确定哪台服务器本地中了缓存，更新或者删除所有服务器的缓存不是一个好的选择，所以我们通常会等待缓存过期。因此，这种缓存的有效期很短，通常为分钟或者秒级别，以避免返回前端脏数据。\n静态缓存如CDN等，后续单独整理。\n缓存的不足首先，缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。这是因为缓存毕竟会受限于存储介质不可能缓存所有数据，那么当数据有热点属性的时候才能保证一定的缓存命中率其次，缓存会给整体系统带来复杂度，并且会有数据不一致的风险。当更新数据库成功，更新缓存失败的场景下，缓存中就会存在脏数据。对于这种场景，我们可以考虑使用较短的过期时间或者手动清理的方式来解决。再次，之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的。因此，我们在使用缓存的时候要做数据存储量级的评估，对于可预见的需要消耗极大存储成本的数据，要慎用缓存方案。同时，缓存一定要设置过期时间，这样可以保证缓存中的会是热点数据。最后，缓存会给运维也带来一定的成本。运维需要对缓存组件有一定的了解，在排查问题的时候也多了一个组件需要考虑在内。1虽然有这么多的不足，但是缓存对于性能的提升是毋庸置疑的，我们在做架构设计的时候也需要把它考虑在内，只是在做具体方案的时候需要对缓存的设计有更细致的思考，才能最大化地发挥缓存的优势。注意问题缓存可以有多层，比如上面提到的静态缓存处在负载均衡层，分布式缓存处在应用层和数据库层之间，本地缓存处在应用层。我们需要将请求尽量挡在上层，因为越往下层，对于并发的承受能力越差；缓存命中率是我们对于缓存最重要的一个监控项，越是热点的数据，缓存的命中率就越高当在实际工作中碰到“慢”的问题时，缓存就是你第一时间需要考虑的。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/huancun.png","plink":"https://snailscoder.com/2020/04/13/architect/cache-01/"},{"title":"高并发系统：数据迁移","date":"2020-04-12T20:59:00.000Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-13T09:22:21.675Z","content":"如何平滑地迁移数据库中的数据迁移过程需要满足以下几个目标：\n迁移应该是在线的迁移，也就是在迁移的同时还会有数据的写入；数据应该保证完整性，也就是说在迁移之后需要保证新的库和旧的库的数据是一致的；迁移的过程需要做到可以回滚，这样一旦迁移的过程中出现问题，可以立刻回滚到源库不会对系统的可用性造成影响。一般来说，我们有两种方案可以做数据库的迁移。\n“双写”方案\n将新的库配置为源库的从库用来同步数据；如果需要将数据同步到多库多表，那么可以使用一些第三方工具获取 Binlog 的增量日志（比如开源工具 Canal），在获取增量日志之后就可以按照分库分表的逻辑写入到新的库表中了。同时我们需要改造业务代码，在数据写入的时候不仅要写入旧库也要写入新库。当然，基于性能的考虑，我们可以异步地写入新库，只要保证旧库写入成功即可。但是我们需要注意的是，需要将写入新库失败的数据记录在单独的日志中，这样方便后续对这些数据补写，保证新库和旧库的数据一致性。然后我们就可以开始校验数据了。由于数据库中数据量很大，做全量的数据校验不太现实。你可以抽取部分数据，具体数据量依据总体数据量而定，只要保证这些数据是一致的就可以。如果一切顺利，我们就可以将读流量切换到新库了。由于担心一次切换全量读流量可能会对系统产生未知的影响，所以这里最好采用灰度的方式来切换，比如开始切换 10% 的流量，如果没有问题再切换到 50% 的流量，最后再切换到 100%。由于有双写的存在，所以在切换的过程中出现任何的问题都可以将读写流量随时切换到旧库去，保障系统的性能。在观察了几天发现数据的迁移没有问题之后，就可以将数据库的双写改造成只写新库，数据的迁移也就完成了。如果是将数据从自建机房迁移到云上，你也可以使用这个方案，只是你需要考虑的一个重要的因素是：自建机房到云上的专线的带宽和延迟，你需要尽量减少跨专线的读操作，所以在切换读流量的时候你需要保证自建机房的应用服务器读取本机房的数据库，云上的应用服务器读取云上的数据库。这样在完成迁移之前，只要将自建机房的应用服务器停掉并且将写入流量都切到新库就可以了。\n\n这种方案是一种比较通用的方案，无论是迁移 MySQL 中的数据还是迁移 Redis 中的数据，甚至迁移消息队列都可以使用这种方式，你在实际的工作中可以直接拿来使用。这种方式的好处是：迁移的过程可以随时回滚，将迁移的风险降到了最低。劣势是：时间周期比较长，应用有改造的成本。\n级联同步方案这种方案也比较简单，比较适合数据从自建机房向云上迁移的场景。因为迁移上云最担心云上的环境和自建机房的环境不一致，会导致数据库在云上运行时因为参数配置或者硬件环境不同出现问题。所以我们会在自建机房准备一个备库，在云上环境上准备一个新库，通过级联同步的方式在自建机房留下一个可回滚的数据库，具体的步骤如下：\n先将新库配置为旧库的从库，用作数据同步；再将一个备库配置为新库的从库，用作数据的备份；等到三个库的写入一致后，将数据库的读流量切换到新库；然后暂停应用的写入，将业务的写入流量切换到新库（由于这里需要暂停应用的写入，所以需要安排在业务的低峰期）。回滚过程如下：\n先将读流量切换到备库再暂停应用的写入将写流量切换到备库，这样所有的流量都切换到了备库，也就是又回到了自建机房的环境，就可以认为已经回滚了。这种方案优势是简单易实施，在业务上基本没有改造的成本；缺点是在切写的时候需要短暂的停止写入，对于业务来说是有损的，不过如果在业务低峰期来执行切写，可以将对业务的影响降至最低。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/114.png","plink":"https://snailscoder.com/2020/04/12/architect/db-06/"},{"title":"高并发系统：数据库优化-NoSQL补充","date":"2020-04-12T17:59:25.000Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-13T03:44:36.583Z","content":"NoSQL 数据库在性能、扩展性上的优势，以及它的一些特殊功能特性，主要有以下几点：\n在性能方面，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写，提升了写的性能；在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持；在扩展性方面，NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。NoSQL 数据库发展到现在，十几年间，出现了多种类型，我来给你举几个例子：\nRedis、LevelDB 这样的 KV 存储。这类存储相比于传统的数据库的优势是极高的读写性能，一般对性能有比较高的要求的场景会使用。Hbase、Cassandra 这样的列式存储数据库。这种数据库的特点是数据不像传统数据库以行为单位来存储，而是以列来存储，适用于一些离线数据统计的场景。MongoDB、CouchDB 这样的文档型数据库。这种数据库的特点是 Schema Free（模式自由），数据表中的字段可以任意扩展，比如说电商系统中的商品有非常多的字段，并且不同品类的商品的字段也都不尽相同，使用关系型数据库就需要不断增加字段支持，而用文档型数据库就简单很多了。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/buchong.jpg","plink":"https://snailscoder.com/2020/04/12/architect/db-05/"},{"title":"高并发系统：数据库优化-分库分表","date":"2020-04-12T12:59:25.000Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-13T03:47:26.437Z","content":"在 4 核 8G 的云服务器上对 MySQL 5.7 做 Benchmark，大概可以支撑 500TPS 和 10000QPS，如果出现写并发量大时，该如何解决？出现数据库容量瓶颈时如何解决？单纯从数据库层面考虑一般采用垂直拆分和水平拆分来解决。数据库分库分表的方式有两种：一种是垂直拆分，另一种是水平拆分。这两种方式，在我看来，掌握拆分方式是关键，理解拆分原理是内核。所以你在学习时，最好可以结合自身业务来思考。\n拆分方式1、垂直拆分垂直拆分，顾名思义就是对数据库竖着拆分，也就是将数据库的表拆分到多个不同的数据库中。垂直拆分的原则一般是按照业务类型来拆分，核心思想是专库专用，将业务耦合度比较高的表拆分到单独的库中。举个形象的例子，就是在整理衣服的时候，将羽绒服、毛衣、T 恤分别放在不同的格子里。这样可以解决我在开篇提到的第三个问题：把不同的业务的数据分拆到不同的数据库节点上，这样一旦数据库发生故障时只会影响到某一个模块的功能，不会影响到整体功能，从而实现了数据层面的故障隔离。现在大多数公司都采用微服务架构，一般方案为按服务拆库，各服务不进行跨库读写数据。\n优点：各业务库独立，可以按业务重要性来区别对待，优先保障核心业务库。缺点：不能解决某一个业务模块的数据大量膨胀的问题\n2、水平拆分和垂直拆分的关注点不同，垂直拆分的关注点在于业务相关性，而水平拆分指的是将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点。一般按业务类型分为两种拆分方式：\n字段哈希值拆分这种拆分规则比较适用于实体表，数据相对独立，无明显时间概念等的数据，比如说用户表，可以先对用户 ID 做哈希（哈希的目的是将 ID 尽量打散）比如拆分成16个库，每库64张表。先对库数量16取余，决定划分到哪个库，后对库中表数量64取余，决定在哪张表。\n字段区间拆分比较常用的是时间字段，比如用户订单等按照下单时间来拆分表，用户查询订单时必须指定查询时间段。该例子不一定是最优方案哈，会存在热点问题，比如双十一一天内订单量超大就会存在问题。\n分库分表引入的问题分库分表引入的一个最大的问题就是引入了分库分表键，也叫做分区键，也就是我们对数据库做分库分表所依据的字段。\n一旦分区后，查询条件中必须带有分区键查询，明确要查询的数据在哪个区才有效，否则会带来更严重的性能问题。现阶段如何解决跨区查询问题呢，本人总结方式如下：1、先查后整合    一般是把两个表的数据取出后在业务代码里面做筛选，复杂是有一些，不过是可以实现的。2、数据冗余    如用户表按用户ID拆分，但需要按用户昵称查询用户的情况。    可以冗余一份用户昵称与用户ID量字段的表，先从该表中按昵称查询ID，再进行ID精准查询。当然该表也可以进行分区。3、借助三方中间件    涉及一些复杂的查询搜索功能，可以借助ElasticSearch等中间件，来进行搜索优化。\n有很多人并没有真正从根本上搞懂为什么要拆分，拆分后会带来哪些问题，只是一味地学习大厂现有的拆分方法，从而导致问题频出。所以，你在使用一个方案解决一个问题的时候一定要弄清楚原理，搞清楚这个方案会带来什么问题，要如何来解决，要知其然也知其所以然，这样才能在解决问题的同时避免踩坑。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/13/109.jpg","plink":"https://snailscoder.com/2020/04/12/architect/db-04/"},{"title":"高并发系统：数据库优化-读写分离","date":"2020-04-12T10:49:25.000Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-12T04:21:17.229Z","content":"依据一些云厂商的 Benchmark 的结果，在 4 核 8G 的机器上运行 MySQL 5.7 时，大概可以支撑 500 的 TPS 和 10000 的 QPS。大部分系统的访问模型是读多写少，读写请求量的差距可能达到几个数量级。当单机MySQL达不到高并发读请求时的处理方案:主从读写分离\n主从读写的两个技术关键点一、主从复制MySQL 的主从复制是依赖于 binlog 的,主从复制就是将 binlog 中的数据从主库传输到从库上。具体过程：\n从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog，并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中而主库也会创建一个 log dump 线程来发送 binlog 给从库；从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性。这是一种比较常见的主从复制方式。主从复制存在的问题数据延时问题为了不影响主库的性能，主从同步为异步过程。不能保障从库无延时同步。主从的一致性和写入性能的权衡如果你要保证所有从节点都写入成功，那么写入性能一定会受影响；如果你只写入主节点就返回成功，那么从节点就有可能出现数据同步失败的情况，从而造成主从不一致，而在互联网的项目中，我们一般会优先考虑性能而不是数据的强一致性。不能无限制增加从库数量增加从库主库会创建log dump线程，消耗主库性能，一般一个主库最多挂 3～5 个从库主从数据延时解决方案参考\n1. 数据冗余    异步消息传输时，不仅仅发送ID，而是发送全量信息，避免从库再次查询.    缺点:可能造成单条消息比较大，从而增加了消息发送的带宽和时间。2. 使用缓存    同步写数据库的同时,将数据写入缓存:如Redis，从Redis中读取。    缺点:更适合新增数据，更新数据需要考虑数据不一致问题\n注意：需要做好从库延时时间的监控，延时过大需要告警通知。正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。\n\n二、程序访问一主多从，读写分离，存在多个数据库节点，程序需要选择性的连接，增加了访问的复杂度。为了降低实现的复杂度，业界涌现了很多数据库中间件来解决数据库的访问问题，这些中间件可以分为两类。\n1. 内嵌组件以淘宝的 TDDL为代表，以代码形式内嵌运行在应用程序内部，你可以把它看成是一种数据源的代理，它的配置管理着多个数据源，每个数据源对应一个数据库，可能是主库，可能是从库。当有一个数据库请求时，中间件将 SQL 语句发给某一个指定的数据源来处理，然后将处理结果返回。优点：简单易用，没有多余的部署成本缺点：缺乏多语言的支持，升级比较困难\n2. 增加代理层单独部署的代理层方案，中间件部署在独立的服务器上，业务代码如同在使用单一数据库一样使用它，实际上它内部管理着很多的数据源，当有数据库请求时，它会对 SQL 语句做必要的改写，然后发往指定的数据源。市面很多成熟中间件，具体可参考：分布式数据库中间件TDDL、Amoeba、Cobar、MyCAT架构比较\n优点：    * 使用标准的 MySQL 通信协议，所以可以很好地支持多语言    * 独立部署，维护升级方便缺点：    * 增加代理层，SQL多跨一层网络，有性能损耗    * 代理层专人维护成本增加\n注意：在使用任何中间件的时候一定要保证对于中间件有足够深入的了解，否则一旦出了问题没法快速地解决就悲剧了。\n\n名词解释QPS：每秒查询数，是针对读请求的TPS：每秒执行事务数，倾向于写请求binlog:记录 MySQL 上的所有变化并以二进制形式保存在磁盘上二进制日志文件扩展Redis主从复制原理总结","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/fenli.png","plink":"https://snailscoder.com/2020/04/12/architect/db-03/"},{"title":"高并发系统：池化技术-Tomcat、Undertow连接池","date":"2020-04-11T23:49:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:16:53.332Z","content":"Tomcat配置核心参数:max-threads:该线程池可以容纳的最大线程数。默认值：200server.tomcat.max-threads=1000max-connections:接受和处理的最大连接数server.tomcat.max-connections=20000min-SpareThreads:Tomcat应该始终打开的最小不活跃线程数。默认值：25。server.tomcat.min-SpareThreads=20acceptCount:可以放到处理队列中的请求数server.tomcat.acceptCount=700connectionTimeout 连接超时server.tomcat.connectionTimeout=1000\nUndertow配置核心参数io-threads:设置IO线程数, 它主要执行非阻塞的任务,它们会负责多个连接, 默认设置每个CPU核心一个线程.不要设置过大，如果过大，启动项目会报错：打开文件数过多server.undertow.io-threads=16\nworker-threads:阻塞任务线程池, 当执行类似servlet请求阻塞IO操作, undertow会从这个线程池中取得线程,它的值设置取决于系统线程执行任务的阻塞系数，默认值是IO线程数*8server.undertow.worker-threads=256\nbuffer-size:该配置会影响buffer,这些buffer会用于服务器连接的IO操作,有点类似netty的池化内存管理,每块buffer的空间大小,越小的空间被利用越充分，不要设置太大，以免影响其他应用，合适即可server.undertow.buffer-size=1024\nbuffers-per-region:每个区分配的buffer数量 , 所以pool的大小是buffer-size * buffers-per-regionserver.undertow.buffers-per-region=1024\ndirect-buffers:是否分配的直接内存(NIO直接分配的堆外内存)server.undertow.direct-buffers=true\n扩展文章SpringBoot服务器压测对比","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/qianbi.jpg","plink":"https://snailscoder.com/2020/04/11/architect/db-02/"},{"title":"高并发系统：池化技术-数据库连接池","date":"2020-04-11T22:49:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:16:58.028Z","content":"数据库连接池与系统线程池不同，数据库连接池并不控制应用端和数据库端的线程池的大小。而且每个数据库连接池的配置只是针对自己所在的应用服务进程，限制的是同一个进程内可以访问数据库的并行线程数目。\n数据库连接池好处节省了创建数据库连接的时间，通常这个时间大大超过处理数据访问请求的时间。统一管理数据库请求连接，避免了过多连接或频繁创建/删除连接带来的性能问题。监控了数据库连接的运行状态和错误报告，减少了应用服务的这部分代码。可以检查和报告不关闭数据库连接的错误，帮助运维监测数据库访问阻塞和帮助程序员写出正确数据库访问代码。连接池优化策略做为应用服务和数据库的桥梁，连接池参数配置的目标是全局优化。具体的优化目的有四个：\n尽可能满足应用服务的并发数据库访问所有需要访问数据库的线程都可以得到需要的数据库连接。如果一个线程用到多个连接，那么需要的连接数目也会成倍增加。这时，需要的连接池最大尺寸应该是最大的并发数据库访问线程数目乘以每个线程需要的连接数目。不让数据库服务器过载可能有多个应用服务器的多个连接池会同时发出请求。能发现用了不还造成的死锁应用程序错误会造成借了不还的情况，反复出现会造成连接池用完应用长期等待甚至死锁的状态。需要有连接借用的超时报错机制，而这个超时时间取决于具体应用。不浪费系统资源。配置过大的连接池会浪费应用服务器的系统资源，包括内存，网络端口，同步信号等。同时线程池的重启和操作都会响应变慢。不过应用端连接池的开销不是很大，资源的浪费通常不是太大问题。核心参数配置此处以Spring默认数据库连接池HikariCP为例：\nmaximum-pool-size:连接池中最大连接数（包括空闲和正在使用的连接）默认值是10，这个一般预估应用的最大连接数，后期根据监测得到一个最大值的一个平均值。要知道，最大连接并不是越多越好，一个connection会占用系统的带宽和存储。但是 当连接池没有空闲连接并且已经到达最大值，新来的连接池请求（HikariPool#getConnection）会被阻塞直到connectionTimeout（毫秒），超时后便抛出SQLException。minimum-idle:池中最小空闲连接数量。默认值10，小于池中最大连接数，一般根据系统大部分情况下的数据库连接情况取一个平均值。Hikari会尽可能、尽快地将空闲连接数维持在这个数量上。如果为了获得最佳性能和对峰值需求的响应能力，我们也不妨让他和最大连接数保持一致，使得HikariCP成为一个固定大小的数据库连接池。pool-name:连接池的名字。一般会出现在日志和JMX控制台中。默认值：auto-genenrated。建议取一个合适的名字，便于监控。auto-commit:是否自动提交池中返回的连接。默认值为true。一般是有必要自动提交上一个连接中的事务的。如果为false，那么就需要应用层手动提交事务。idle-timeout:空闲时间。仅在minimum-idle小于maximum-poop-size的时候才会起作用。默认值10分钟。根据应用实际情况做调整，对于一些间歇性流量达到峰值的应用，一般需要考虑设置的比间歇时间更大，防止创建数据库连接拖慢了应用速度。max-lifetime:连接池中连接的最大生命周期。当连接一致处于闲置状态时，数据库可能会主动断开连接。为了防止大量的同一时间处于空闲连接因为数据库方的闲置超时策略断开连接（可以理解为连接雪崩），一般将这个值设置的比数据库的“闲置超时时间”小几秒，以便这些连接断开后，HikariCP能迅速的创建新一轮的连接。connection-timeout:连接超时时间。默认值为30s，可以接收的最小超时时间为250ms。但是连接池请求也可以自定义超时时间（com.zaxxer.hikari.pool.HikariPool#getConnection(long)）。连接创建策略&lt;minimum-idle:如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；如果连接池中有空闲连接则复用空闲连接；&gt;minimum-idle,&lt;maximum-pool-size:如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；&gt;=maximum-pool-size:如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间等待旧的连接可用；如果等待超过了这个设定时间则向用户抛出错误。\n参考文章数据库连接池设置HikariCP重要参数配置","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/mg6431.jpg","plink":"https://snailscoder.com/2020/04/11/architect/db-01/"},{"title":"高并发系统：池化技术-JDK线程池","date":"2020-04-11T22:39:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:17:10.055Z","content":"JDK 实现的这个线程池优先把任务放入队列暂存起来，而不是创建更多的线程，它比较适用于执行 CPU 密集型的任务，也就是需要执行大量 CPU 运算的任务。这是为什么呢？因为执行 CPU 密集型的任务时 CPU 比较繁忙，因此只需要创建和 CPU 核数相当的线程就好了，多了反而会造成线程上下文切换，降低任务执行效率。所以当前线程数超过核心线程数时，线程池不会增加线程，而是放在队列里等待核心线程空闲下来。\n一般核心线程数与CPU核数一致，计算公式：线程数目 = CPU核数 * CPU 利用率 * (1 + 等待时间 / CPU计算时间)\nJDK线程池核心参数12345678&#x2F;&#x2F;java.util.concurrent.ThreadPoolExecutorpublic ThreadPoolExecutor(int corePoolSize,                              int maximumPoolSize,                              long keepAliveTime,                              TimeUnit unit,                              BlockingQueue&lt;Runnable&gt; workQueue,                              ThreadFactory threadFactory,                              RejectedExecutionHandler handler)corePoolSize:线程池中的核心线程数,即使没有任务执行的时候,他们也是存在的.(不考虑配置了参数:allowCoreThreadTimeOut,allowCoreThreadTimeOut通过字面意思也能知道,就是是否允许核心线程超时,一般情况下不需要设置,本文不考虑)maximumPoolSize:线程池中的允许存在的最大线程数keepAliveTime:当线程池中的线程超过核心线程数的时候,这部分多余的空闲线程等待执行新任务的超时时间.例如:核心线程数为1 ,最大线程数为5,当前运行线程为4,keepAliveTime为60s,那么4-1=3个线程在空闲状态下等待60s 后还没有新任务到来,就会被销毁了.unit:keepAliveTime 的时间单位workQueue: 线程队列,如果当前时间核心线程都在运行,又来了一个新任务,那么这个新任务就会被放进这个线程队列中,等待执行.threadFactory: 线程池创建线程的工厂类.handler: 如果线程队列满了同事执行线程数也达到了maximumPoolSize,如果此时再来新的线程,将执行什么 handler 来处理这个线程. handler的默认提供的类型有:AbortPolicy: 抛出RejectedExecutionException异常DiscardPolicy: 什么都不做.DiscardOldestPolicy: 将线程队列中的最老的任务抛弃掉,换区一个空间执行当前的任务.CallerRunsPolicy: 使用当前的线程(比如 main)来执行这个线程.JDK线程创建回收策略&lt;corePoolSize:如果新加入一个运行的任务,当前运行的线程小于corePoolSize,这时候会在线程池中新建一个线程用于执行这个新的任务.&gt;corePoolSize,队列不满:如果新加入一个运行的任务,当前运行的线程大于等于corePoolSize,这个时候就需要将这个新的任务加入到线程队列workQueue中,一旦线程中的线程执行完成了一个任务,就会马上从队列中去一个任务来执行.&gt;corePoolSize,&lt;maximumPoolSize:如果队列也满了,怎么办呢? 如果maximumPoolSize大于corePoolSize,就会新建线程来处理这个新的任务,直到总运行线程数达到maximumPoolSize.&gt;maximumPoolSize:如果总运行线程数达到了maximumPoolSize,还来了新的任务怎么办呢?就需要执行上面所说的拒绝策略了handler了,按照配置的策略进行处理,默认不配置的情况下,使用的是AbortPolicy.keepAliveTime:超过corePoolSize的线程，在空闲时间超过keepAliveTime时会被释放allowCoreThreadTimeOut:在配置了allowCoreThreadTimeOut时，corePoolSize线程在空闲时也会释放，一般不配置。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/pexelsphoto1040161.jpeg","plink":"https://snailscoder.com/2020/04/11/architect/intro-04/"},{"title":"高并发系统：系统可用性的度量","date":"2020-04-11T19:39:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:03:30.519Z","content":"衡量指标可用性是一个抽象的概念，你需要知道要如何来度量它，与之相关的概念是：MTBF 和 MTTR。\nMTBF（Mean Time Between Failure） 是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。\nMTTR（Mean Time To Repair）表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。\n系统可用性指标： Availability = MTBF / (MTBF + MTTR)这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。\n三个九之后，系统的年故障时间从 3 天锐减到 8 小时。四个九之后，年故障时间缩减到 1 小时之内。在这个级别的可用性下，你可能需要建立完善的运维值班体系、故障处理流程和业务变更流程。你可能还需要在系统设计上有更多的考虑。比如，在开发中你要考虑，如果发生故障，是否不用人工介入就能自动恢复。当然了，在工具建设方面，你也需要多加完善，以便快速排查故障原因，让系统快速恢复。五个九之后，故障就不能靠人力恢复了。想象一下，从故障发生到你接收报警，再到你打开电脑登录服务器处理问题，时间可能早就过了十分钟了。所以这个级别的可用性考察的是系统的容灾和自动恢复的能力，让机器来处理故障，才会让可用性指标提升一个档次。设计思路系统设计failover（故障转移）心跳监测，故障转移超时控制通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的，然后依据这个时间来指定超时时间降级降级是为了保证核心服务的稳定而牺牲非核心服务的做法。限流通过对并发的请求进行限速来保护系统系统运维灰度发布灰度发布指的是系统的变更不是一次性地推到线上的，而是按照一定比例逐步推进的。故障演练故障演练指的是对系统进行一些破坏性的手段，观察在出现局部故障时，整体的系统表现是怎样的，从而发现系统中存在的，潜在的可用性问题。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/1.png","plink":"https://snailscoder.com/2020/04/11/architect/intro-03/"},{"title":"高并发系统：经典分层举例","date":"2020-04-11T17:39:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T03:03:30.526Z","content":"1.应用三层架构\n表现层：顾名思义嘛，就是展示数据结果和接受用户指令的，是最靠近用户的一层；逻辑层：里面有复杂业务的具体实现；数据访问层则：是主要处理和存储之间的交互。\n2.网络分层架构\nOSI 网络模型，它把整个网络分成了七层，自下而上分别是物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。TCP/IP 协议，它把网络简化成了四层，即链路层、网络层、传输层和应用层。每一层各司其职又互相帮助，网络层负责端到端的寻址和建立连接，传输层负责端到端的数据传输等，同时相邻两层还会有数据的交互。这样可以隔离关注点，让不同的层专注做不同的事情。\n3.Linux文件系统分层\n在文件系统的最上层是虚拟文件系统（VFS），用来屏蔽不同的文件系统之间的差异，提供统一的系统调用接口。虚拟文件系统的下层是 Ext3、Ext4 等各种文件系统，再向下是为了屏蔽不同硬件设备的实现细节，我们抽象出来的单独的一层——通用块设备层，然后就是不同类型的磁盘了。\n\n4.阿里系统分层规约\n终端显示层：各端模板渲染并执行显示的层。当前主要是 Velocity 渲染，JS 渲染， JSP 渲染，移动端展示等。开放接口层：将 Service 层方法封装成开放接口，同时进行网关安全控制和流量控制等。Web 层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。Service 层：业务逻辑层。Manager 层：通用业务处理层。这一层主要有两个作用，其一，你可以将原先 Service 层的一些通用能力下沉到这一层，比如与缓存和存储交互策略，中间件的接入；其二，你也可以在这一层封装对第三方接口的调用，比如调用支付服务，调用审核服务等。DAO 层：数据访问层，与底层 MySQL、Oracle、HBase 等进行数据交互。外部接口或第三方平台：包括其它部门 RPC 开放接口，基础平台，其它公司的 HTTP 接口。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/haibian.jpg","plink":"https://snailscoder.com/2020/04/11/architect/intro-02/"},{"title":"高并发系统：通用设计方法","date":"2020-04-11T16:56:25.000Z","date_formatted":{"ll":"2020年4月11日","L":"2020/04/11","MM-DD":"04-11"},"updated":"2020-04-12T02:51:20.404Z","content":"洪水猛兽通常如何治理洪水，方案如下：\n分流：将水分流到多个支流中，以分担水流压力提高流速： 拓宽河道，清除淤沙让流水更加顺畅水库：将水引入水库先存储起来，然后再想办法把水库中的水缓缓地排出去，以此提高下游的抗洪能力高并发高并发就像洪水猛兽，处理方案类似：\n横向扩展：分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击。异步：在某些场景下，未处理完成之前我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。\n方案一：Scale-out（横向扩展）系统分布式设计，横向扩展，增加节点。微服务：SpringCloud\n方案二：缓存为什么使用缓存？普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都是在 ns（纳秒）级别，从千兆网卡上读取数据的时间是在μs（微秒）级别。所以在整个计算机体系中磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此我们通常使用以内存作为存储介质的缓存，以此提升性能。Redis\n方案三：异步调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。Reactive三方消息：RabbitMQ，Kafka，RocketMQ，ActiveMQ等\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/01/img1276.png","plink":"https://snailscoder.com/2020/04/11/architect/Intro-01/"},{"title":"学会承受人生必然的孤独，过了才能看见美好繁华！","date":"2020-04-03T16:38:25.000Z","date_formatted":{"ll":"2020年4月3日","L":"2020/04/03","MM-DD":"04-03"},"updated":"2020-04-12T04:23:27.157Z","content":"人生语录：学会承受人生必然的孤独，过了才能看见美好繁华！\n分享一段特别好的话：“爱好，是可以救命的”，当你人生迷茫困惑的时候，不要停下来，去做你喜欢的事情，忙碌起来，改变心境，你会逐渐发现，一切居然豁然开朗起来…生活中有很多不容易，却阻挡不了任何一个热爱生活的人去散发光芒。\n身边朋友纵然很多，但如若没有合拍的，在一起时内心想必也是孤独的。不合无意义的群。孤独虽然如影随形，但不必惧怕它，它是你生活中不可或缺的一部分，试着与它相处吧。孤独不是贬义词，当一个人的时候，可以思考自己的事情，欣赏喜欢的电影。或者培养一个爱好吧，也许在喜欢的领域里会交到更合拍的朋友。耐得住寂寞，才能享的了长远。\n真正想要的东西，不只是踮踮脚尖那么简单，所有的收获，一定要全力以赴，奋不顾身。 人生没有多走的路，脚下的每一步都算数。没有不请自来的幸运，只有有备而来的惊艳。没有人能定义你的未来，除了你自己。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/12/gudu.png","plink":"https://snailscoder.com/2020/04/03/notes/2020-04-03/"},{"title":"东小口森林公园-花朵","date":"2020-04-02T17:51:00.000Z","date_formatted":{"ll":"2020年4月2日","L":"2020/04/02","MM-DD":"04-02"},"updated":"2020-04-12T04:16:36.817Z","content":"裁剪前\n裁剪后\n自行车，拍的很不好看。水平欠佳\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/01/dsc0346.jpg","plink":"https://snailscoder.com/2020/04/02/travel/dxk/"},{"title":"个人博客Nginx强制跳转Https配置","date":"2020-04-01T19:38:25.000Z","date_formatted":{"ll":"2020年4月1日","L":"2020/04/01","MM-DD":"04-01"},"updated":"2020-04-01T12:25:46.588Z","content":"今日因需要将自己的博客域名加入https支持，并把之前的HTTP访问强制跳转到HTTPS。\n1、nginx支持https如果起初nginx编译时没有添加ssl支持，需要对nginx重新编译，增加http_ssl_module模块\n12345671.配置.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --with-http_stub_status_module --with-http_ssl_module2.编译安装make &amp;&amp; make install2、配置https域及SSL证书没有证书的可以考虑腾讯云申请免费证书，但仅限单域名,申请地址:https://cloud.tencent.com/product/ssl,申请通过后，下载nginx专用证书。以下为https证书相关配置\n123456789101112server &#123;    listen       443 ssl;    server_name  www.snailscoder.com;    ssl_certificate      ..&#x2F;ssl&#x2F;***.crt;    ssl_certificate_key  ..&#x2F;ssl&#x2F;***.key;    ssl_session_cache    shared:SSL:1m;    ssl_session_timeout  5m;    location &#x2F; &#123;        root   html;        index  index.html index.htm;    &#125;&#125;配置好后，测试https是否可以正常访问。\n3、http强制跳转https此处因http下无其他信息，单纯配置了跳转\n12345678910server &#123;    listen       80;    server_name  www.snailscoder.com;    #方式一    return      301 https:&#x2F;&#x2F;$server_name$request_uri;    #方式二    #rewrite ^&#x2F;(.*)$ https:&#x2F;&#x2F;www.snailscoder.com&#x2F;$1 permanent;    #方式三    #rewrite ^ https:&#x2F;&#x2F;www.snailscoder.com$request_uri? permanent;&#125;博客内容较简单，仅为个人配置记录，有问题可留言咨询。有更好的方案，也请多多指教。\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/01/img1276.png","plink":"https://snailscoder.com/2020/04/01/http/nginx-rewrite/"},{"title":"Java虚拟机总结思维导图","date":"2020-04-01T19:38:25.000Z","date_formatted":{"ll":"2020年4月1日","L":"2020/04/01","MM-DD":"04-01"},"updated":"2020-04-01T12:24:41.066Z","content":"\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/04/01/wnlpc.png","plink":"https://snailscoder.com/2020/04/01/java/100001/"},{"title":"闲逛景山","date":"2020-03-31T21:51:00.000Z","date_formatted":{"ll":"2020年3月31日","L":"2020/03/31","MM-DD":"03-31"},"updated":"2020-04-12T04:16:36.854Z","content":"盛开的梅花\n远望故宫博物院\n园中肥野猫\n寂静的街头\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/31/dsc0562.jpg","plink":"https://snailscoder.com/2020/03/31/travel/jingshan/"},{"title":"Java中flag和flag==true的区别","date":"2020-03-21T21:56:25.000Z","date_formatted":{"ll":"2020年3月21日","L":"2020/03/21","MM-DD":"03-21"},"updated":"2020-04-01T12:24:46.477Z","content":"有如下 Test.java 文件\n123456789public class Test &#123;     public static void main(String[] args) &#123;          boolean flag &#x3D; true;          if (flag)             System.out.println(&quot;Hello, Java!&quot;);          if (flag &#x3D;&#x3D; true)                   System.out.println(&quot;Hello, JVM!&quot;);     &#125;&#125;此处 flag和flag == true大家认为有区别吗？\n下边让我们来见证一下奇迹:\njavac Foo.java 命令生成 Foo.class 文件，使用 JD-GUI 打开内容如下：\n123456789101112131415import java.io.PrintStream;public class Foo&#123;  public static void main(String[] paramArrayOfString)  &#123;    int i &#x3D; 1;    if (i !&#x3D; 0) &#123;      System.out.println(&quot;Hello, Java!&quot;);    &#125;    if (i &#x3D;&#x3D; 1) &#123;      System.out.println(&quot;Hello, JVM!&quot;);    &#125;  &#125;&#125;大家看到不同之处了吗？\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/21/9a15a3bb8de2b97650bf14ff310e39ac.jpg","plink":"https://snailscoder.com/2020/03/21/java/100000/"},{"title":"北海公园之游","date":"2020-03-21T11:56:25.000Z","date_formatted":{"ll":"2020年3月21日","L":"2020/03/21","MM-DD":"03-21"},"updated":"2020-04-12T04:16:36.845Z","content":"\n\n\n\n\n","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/31/bh20200320.jpg","plink":"https://snailscoder.com/2020/03/21/travel/beihai/"},{"title":"一条SQL查询语句是如何执行的","date":"2020-03-20T21:56:25.000Z","date_formatted":{"ll":"2020年3月20日","L":"2020/03/20","MM-DD":"03-20"},"updated":"2020-04-12T03:17:36.932Z","content":"\nMySQL 的逻辑架构图\n连接器查询缓存分析器优化器执行器","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/31/38dd4b12f16d2f9667fb169be0f0698b.jpg","plink":"https://snailscoder.com/2020/03/20/mysql/select-run/"},{"title":"疫情下的颐和园","date":"2020-03-20T10:56:25.000Z","date_formatted":{"ll":"2020年3月20日","L":"2020/03/20","MM-DD":"03-20"},"updated":"2020-04-12T04:16:35.273Z","content":"疫情期间的颐和园，人烟稀少，却是风光无限，沉淀出了时光的痕迹。择一日，春光曼妙，风和日丽，漫步园中，岁月静好。\n园内风景十七孔桥\n远观玉峰塔\n清净的湖面，风景美不胜收\n盛开的山桃花\n远眺佛香阁\n再现十七孔桥\n零星的观景人\n昔日吵闹的长廊\n阳春三月，昔日人流如织，如今….\n没有游船，只有野鸭、黑天鹅;没有商店，没有泡面、火腿;\n人烟稀少，却是风光无限。\n希望疫情早点结束…\n入园攻略提前一天“颐和园”官方微信公众号进行预约购票，可预约上午、下午两个时段，不预约不能进。第二天直接刷身份证入园（一定要带身份证！！）疫情期间只有新建宫门开放，其他都是关闭的。开车前往的旁边有6-7号停车场，方便停车。","thumbnail":"https://blogimg-1254014761.cos.ap-beijing.myqcloud.com/2020/03/20/shi-qi-kong-qiao.jpg","plink":"https://snailscoder.com/2020/03/20/travel/yhy/"},{"title":"关于’蜗码‘","date":"2020-04-12T12:32:22.880Z","date_formatted":{"ll":"2020年4月12日","L":"2020/04/12","MM-DD":"04-12"},"updated":"2020-04-02T03:31:31.343Z","content":"博客来由我们每个人的在网络上产生的数据越来越多，这些信息是我们在互联网上存在过的痕迹，值得我们认真对待。但是它们被分散分布在各个网站上。很多时候我们很难将它们聚合在一起，而且各个网站的信息排布方式也没有办法自由控制，所以我们需要一个可以由自己主宰的空间——博客。\n通过博客，我们可以记录自己的生活和成长的轨迹。它不像 Twitter 那样碎片化，也不像 Facebook 那样关系化，它是私人的空间。\n关于’蜗码‘蜗牛，一步一个脚印的向自己的目标爬行.蜗码，像蜗牛一样的码农，让自己像蜗牛一样，踏踏实实的进步，不再浮躁。\n博客平台博客： Hexo部署： GitHub Pages主题： inside评论： Gitalk\n","plink":"https://snailscoder.com/about/"}]